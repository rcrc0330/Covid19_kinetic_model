103
rm: cannot remove 'UGP-7thsem/temp_dist/my': Is a directory
rm: cannot remove 'UGP-7thsem/temp_dist/plot': Is a directory
   1.0738093e-01
   1.3564674e-01
   3.8757451e-01
   1.7407959e-03
   5.4494080e-04
   2.5562440e+06
   3.2068880e-05
   4.2708108e-03
   3.6809472e+01
   4.0375989e-04
   4.9019000e+04


                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'TN_Tenkasi'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_TN_Tenkasi (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_TN_Tenkasi (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.227477                           321
[Warning: Failure at t=7.650467e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_TN_Tenkasi>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_TN_Tenkasi (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_TN_Tenkasi>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_TN_Tenkasi (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MH_Thane'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Thane (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Thane (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.058302                          11.9
[Warning: Failure at t=1.949381e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MH_Thane>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MH_Thane (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MH_Thane>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MH_Thane (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'UP_Moradabad'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Moradabad (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Moradabad (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         5.90413                      2.16e+03
     1         12         5.90413       0.683814       2.16e+03      
     2         18          1.8897       0.170954            724      
     3         24        0.287064       0.238989           41.8      
     4         30        0.287064       0.218909           41.8      
[Warning: Failure at t=8.283674e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_UP_Moradabad>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_UP_Moradabad (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_UP_Moradabad>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_UP_Moradabad (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'HR_Hisar'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_HR_Hisar (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_HR_Hisar (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6       0.0223867                          2.17
[Warning: Failure at t=1.840587e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_HR_Hisar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_HR_Hisar (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_HR_Hisar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_HR_Hisar (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MH_Pune'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Pune (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Pune (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.117269                          3.62
[Warning: Failure at t=4.236091e+00.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.421085e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MH_Pune>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MH_Pune (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MH_Pune>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MH_Pune (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MH_Sangli'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Sangli (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Sangli (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6          0.1128                          60.9
[Warning: Failure at t=1.778491e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MH_Sangli>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MH_Sangli (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MH_Sangli>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MH_Sangli (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Chhindwara'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Chhindwara (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Chhindwara (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         100.312                       1.2e+05
[Warning: Failure at t=2.183002e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Chhindwara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Chhindwara (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_MP_Chhindwara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Chhindwara (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'UP_Hardoi'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Hardoi (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Hardoi (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         67.6355                      4.04e+04
     1         12         2.18791       0.235484            895      
     2         18       0.0643277       0.121647           26.1      
     3         24       0.0643277       0.133457           26.1      
     4         30        0.023436      0.0333643            4.6      
     5         36        0.023436      0.0667285            4.6      
     6         42       0.0204847      0.0166821          0.647      
     7         48       0.0192453      0.0166821           1.28      
     8         54       0.0192453      0.0333643           1.28      
     9         60       0.0182915     0.00834107          0.886      
    10         66       0.0169856      0.0166821          0.886      
    11         72       0.0169129      0.0166821          0.575      
    12         78        0.016107     0.00417053           1.37      
    13         84        0.015506     0.00417053           1.08      
    14         90       0.0150761     0.00417053          0.967      
    15         96        0.014772     0.00417053          0.755      
    16        102       0.0145925     0.00417053          0.589      
    17        108       0.0145388     0.00417053          0.441      
    18        114       0.0145371     0.00417053          0.364      
    19        120       0.0145129     0.00104263          0.353      
    20        126       0.0144971     0.00104263          0.263      
    21        132        0.014488     0.00104263          0.184      
    22        138        0.014484     0.00104263          0.149      
    23        144       0.0144816    0.000260658          0.111      
    24        150       0.0144805    6.51646e-05         0.0865      
    25        156       0.0144787    1.62911e-05         0.0109      
    26        162       0.0144787    3.25823e-05         0.0118      
    27        168       0.0144787    8.14557e-06        0.00897      
    28        174       0.0144787    8.14557e-06        0.00676      
    29        180       0.0144787    8.14557e-06        0.00517      
    30        186       0.0144787    8.14557e-06        0.00387      
    31        192       0.0144787    8.14557e-06          0.003      
    32        198       0.0144787    8.14557e-06        0.00224      
    33        204       0.0144787    8.14557e-06        0.00177      
    34        210       0.0144787    8.14557e-06         0.0013      
    35        216       0.0144787    8.14557e-06        0.00106      
    36        222       0.0144787    8.14557e-06       0.000773      
    37        228       0.0144787    8.14557e-06        0.00066      
    38        234       0.0144787    1.62911e-05         0.0005      
    39        240       0.0144787    3.25823e-05       0.000397      
    40        246       0.0144787    3.47442e-05       0.000397      
    41        252       0.0144787    8.14557e-06       0.000329      
    42        258       0.0144787    8.14557e-06       0.000268      
    43        264       0.0144787    2.03639e-06       0.000217      
    44        270       0.0144787    2.03639e-06       0.000157      
    45        276       0.0144787    2.03639e-06       0.000157      
    46        282       0.0144787    5.09098e-07       0.000157      
    47        288       0.0144787    1.27275e-07       0.000157      
    48        294       0.0144787    3.18186e-08       2.53e-05      
    49        300       0.0144787    3.18186e-08       2.53e-05      
    50        306       0.0144787    7.95466e-09       2.53e-05      
    51        312       0.0144787    1.98867e-09       2.03e-05      
    52        318       0.0144787    1.98867e-09       1.55e-05      
    53        324       0.0144787    4.97166e-10       1.43e-05      
    54        330       0.0144787    1.24292e-10        1.4e-05      
    55        336       0.0144787    3.10729e-11        1.4e-05      
    56        342       0.0144787    7.76822e-12       1.39e-05      
    57        348       0.0144787    1.94206e-12       1.39e-05      
    58        354       0.0144787    4.85514e-13       1.39e-05      
    59        360       0.0144787    1.21379e-13       1.39e-05      
    60        366       0.0144787    3.03446e-14       1.39e-05      
    61        372       0.0144787    7.58616e-15       1.39e-05      
    62        378       0.0144787    1.89654e-15       1.39e-05      
    63        384       0.0144787    4.74135e-16       1.39e-05      
    64        390       0.0144787    1.18534e-16       1.39e-05      
    65        396       0.0144787    2.96334e-17       1.39e-05      

Local minimum possible.
lsqnonlin stopped because the size of the current step is less than
the value of the step size tolerance.


kpar =

    0.1032
    0.1677
    0.0191
    0.0026
    0.0028


resnorm =

    0.0145


kpar =

    0.1032
    0.1677
    0.0191
    0.0026
    0.0028


N =

     4091380

{Unrecognized function or variable 'err'.

Error in optimize_UP_Hardoi (line 100)
err
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'CT_Surajpur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Surajpur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Surajpur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.832874                      1.33e+03
     1         12        0.832874       0.954106       1.33e+03      
     2         18        0.224795       0.238527            100      
[Warning: Failure at t=7.578746e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_CT_Surajpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_CT_Surajpur (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_CT_Surajpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_CT_Surajpur (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'KA_Shivamogga'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KA_Shivamogga (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KA_Shivamogga (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6       0.0954165                          54.7
[Warning: Failure at t=3.465249e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_KA_Shivamogga>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_KA_Shivamogga (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_KA_Shivamogga>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_KA_Shivamogga (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GJ_Chhota_Udaipur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Chhota_Udaipur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Chhota_Udaipur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         207.066                      3.65e+04
     1         12           36.05      0.0637122       6.91e+03      
[Warning: Failure at t=1.739348e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_GJ_Chhota_Udaipur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_GJ_Chhota_Udaipur (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_GJ_Chhota_Udaipur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_GJ_Chhota_Udaipur (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GA_Unknown'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GA_Unknown (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GA_Unknown (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_GA_Unknown (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'BR_Kishanganj'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Kishanganj (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Kishanganj (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         41.7128                      4.44e+04
     1         12         41.7128        0.51615       4.44e+04      
     2         18         10.8526       0.129038       1.05e+04      
     3         24        0.474623       0.258075           16.2      
     4         30        0.474623        0.51615           16.2      
     5         36        0.474623       0.129038           16.2      
     6         42        0.474623      0.0322594           16.2      
     7         48        0.345804     0.00806485           24.4      
     8         54        0.330932     0.00806485           17.8      
     9         60        0.326924     0.00201621           32.6      
    10         66           0.303    0.000504053           14.8      
    11         72         0.29696     0.00117789           15.2      
    12         78        0.282278     0.00100811           11.1      
    13         84        0.276761     0.00100811           11.9      
    14         90        0.272382     0.00100811           19.1      
    15         96        0.264576     0.00100811           10.5      
    16        102        0.261848     0.00100811           18.7      
    17        108        0.255348    0.000252026           6.35      
    18        114        0.252748    0.000504053            8.5      
    19        120        0.250229    0.000504053           11.2      
    20        126        0.247425    0.000504053           7.58      
    21        132        0.245578    0.000504053           11.4      
    22        138        0.243037    0.000504053           7.41      
    23        144        0.241473    0.000504053           10.9      
    24        150        0.239265    0.000504053           7.15      
    25        156          0.2379    0.000504053           10.3      
    26        162        0.236009    0.000504053           6.83      
    27        168        0.234798    0.000504053           9.54      
    28        174        0.233175    0.000504053           6.47      
    29        180        0.232079    0.000504053            8.8      
    30        186        0.230676    0.000504053           6.09      
    31        192        0.229678    0.000504053           8.08      
    32        198        0.228473    0.000504053           5.74      
    33        204        0.227579    0.000504053           7.46      
    34        210        0.226536    0.000504053           5.41      
    35        216        0.225733    0.000504053           6.89      
    36        222        0.224824    0.000504053            5.1      
    37        228        0.224102    0.000504053           6.38      
    38        234        0.223303    0.000504053           4.81      
    39        240        0.222651    0.000504053           5.92      
    40        246        0.221945    0.000504053           4.54      
    41        252        0.221359    0.000504053           5.52      
    42        258        0.220734    0.000504053            4.3      
    43        264          0.2202    0.000504053           5.15      
    44        270        0.219639    0.000504053           4.08      
    45        276        0.219149    0.000504053           4.82      
    46        282        0.218642    0.000504053           3.88      
    47        288        0.218191    0.000504053           4.53      
    48        294         0.21773    0.000504053            3.7      
    49        300        0.217314    0.000504053           4.26      
    50        306        0.216892    0.000504053           3.54      
    51        312        0.216506    0.000504053           4.03      
    52        318        0.216117    0.000504053           3.39      
    53        324        0.215757    0.000504053           3.82      
    54        330        0.215398    0.000504053           3.26      
    55        336        0.215061    0.000504053           3.63      
    56        342        0.214727    0.000504053           3.14      
    57        348        0.214411    0.000504053           3.46      
    58        354        0.214104    0.000504053           3.04      
    59        360        0.213809    0.000504053           3.33      
    60        366        0.213517    0.000504053           2.94      
    61        372        0.213238    0.000504053           3.19      
    62        378        0.212962    0.000504053           2.86      
    63        384        0.212697    0.000504053           3.07      
    64        390        0.212437    0.000504053           2.78      
    65        396        0.212185    0.000504053           2.95      
    66        402         0.21194    0.000504053            2.7      
    67        408          0.2117    0.000504053           2.85      
    68        414        0.211466    0.000504053           2.63      
    69        420        0.211237    0.000504053           2.75      
    70        426        0.211014    0.000504053           2.57      
    71        432        0.210795    0.000504053           2.66      
    72        438        0.210583    0.000504053            2.5      
    73        444        0.210372    0.000504053           2.58      
    74        450        0.210169    0.000504053           2.44      
    75        456        0.209968    0.000504053            2.5      
    76        462        0.209774    0.000504053           2.39      
    77        468         0.20958    0.000504053           2.42      
    78        474        0.209395    0.000504053           2.33      
    79        480        0.209209    0.000504053           2.35      
    80        486        0.209031    0.000504053           2.28      
    81        492        0.208852    0.000504053           2.28      
    82        498        0.208682    0.000504053           2.22      
    83        504         0.20851    0.000504053           2.21      
    84        510        0.208346    0.000504053           2.17      
    85        516        0.208181    0.000504053           2.14      
    86        522        0.208024    0.000504053           2.12      
    87        528        0.207866    0.000504053           2.08      
    88        534        0.207715    0.000504053           2.07      
    89        540        0.207562    0.000504053           2.02      
    90        546        0.207418    0.000504053           2.01      
    91        552         0.20727    0.000504053           1.95      
    92        558        0.207131    0.000504053           1.96      
    93        564        0.206989    0.000504053           1.89      
    94        570        0.206856    0.000504053            1.9      
    95        576        0.206719    0.000504053           1.83      
    96        582         0.20659    0.000504053           1.85      
    97        588        0.206458    0.000504053           1.77      
    98        594        0.206335    0.000504053           1.79      
    99        600        0.206207    0.000504053           1.71      
   100        606        0.206088    0.000504053           1.74      
   101        612        0.205966    0.000504053           1.65      
   102        618        0.205851    0.000504053           1.68      
   103        624        0.205729    0.000504053           1.58      
   104        630        0.205535     0.00100811           1.68      
   105        636        0.205168     0.00201621           1.39      
   106        642        0.204536     0.00403242           1.84      
   107        648        0.203362     0.00806485          0.581      
   108        654        0.201837      0.0161297           4.46      
   109        660        0.200359      0.0161297           2.44      
   110        666        0.199438      0.0161297          0.253      
   111        672        0.199438      0.0322594          0.253      
   112        678        0.199275     0.00806485           2.43      
   113        684        0.199052     0.00806485          0.617      
   114        690        0.199052     0.00806485          0.617      
   115        696        0.198997     0.00201621          0.573      
   116        702        0.198965     0.00201621          0.135      
   117        708        0.198947     0.00201621           0.31      
   118        714        0.198925     0.00403242          0.296      
   119        720        0.198925     0.00403242          0.296      
   120        726         0.19892     0.00100811          0.126      
   121        732        0.198918     0.00100811          0.194      
   122        738        0.198917     0.00100811         0.0322      
   123        744        0.198917     0.00100811         0.0322      
   124        750        0.198917    0.000252026         0.0585      
   125        756        0.198917    0.000252026         0.0585      
   126        762        0.198917    6.30066e-05         0.0379      
   127        768        0.198917    6.30066e-05          0.032      
   128        774        0.198917    6.30066e-05          0.032      
   129        780        0.198917    1.57517e-05         0.0203      
   130        786        0.198917    1.57517e-05         0.0149      
   131        792        0.198917    3.93791e-06        0.00972      
   132        798        0.198917    3.93791e-06        0.00659      
   133        804        0.198917    3.93791e-06         0.0046      
   134        810        0.198917    3.93791e-06        0.00327      
   135        816        0.198917    9.84478e-07        0.00217      
   136        822        0.198917    9.84478e-07        0.00142      
   137        828        0.198917     2.4612e-07       0.000934      
   138        834        0.198917     2.4612e-07       0.000934      
   139        840        0.198917    6.15299e-08       0.000934      
   140        846        0.198917    1.73651e-08       0.000934      
   141        852        0.198917    3.84562e-09       0.000598      
   142        858        0.198917    3.84562e-09       0.000263      
   143        864        0.198917    3.84562e-09       0.000263      
   144        870        0.198917    9.61405e-10       0.000263      
   145        876        0.198917    2.40351e-10       0.000242      
   146        882        0.198917    6.00878e-11       0.000242      
   147        888        0.198917    1.50219e-11       0.000241      
   148        894        0.198917    3.75549e-12       0.000241      
   149        900        0.198917    9.38872e-13       0.000241      
   150        906        0.198917    2.34718e-13       0.000241      
   151        912        0.198917    5.86795e-14       0.000241      
   152        918        0.198917    1.46699e-14       0.000241      
   153        924        0.198917    3.66747e-15       0.000241      
   154        930        0.198917    9.16867e-16       0.000241      
   155        936        0.198917    2.29217e-16       0.000241      
   156        942        0.198917    5.73042e-17       0.000241      

Local minimum possible.
lsqnonlin stopped because the size of the current step is less than
the value of the step size tolerance.


kpar =

    0.1026
    0.2236
    0.0150
    0.0018
    0.0022


resnorm =

    0.1989


kpar =

    0.1026
    0.2236
    0.0150
    0.0018
    0.0022


N =

     1690948

{Unrecognized function or variable 'err'.

Error in optimize_BR_Kishanganj (line 100)
err
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Neemuch'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Neemuch (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Neemuch (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         3.29058                      3.64e+03
[Warning: Failure at t=3.630003e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Neemuch>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Neemuch (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MP_Neemuch>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Neemuch (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Churu'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Churu (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Churu (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         34.7797                      2.57e+04
     1         12       0.0955923       0.373424           24.1      
     2         18       0.0955923       0.271899           24.1      
     3         24        0.052233      0.0679747           1.52      
[Warning: Failure at t=6.064750e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_RJ_Churu>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_RJ_Churu (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_RJ_Churu>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Churu (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'KL_Kollam'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KL_Kollam (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KL_Kollam (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6       0.0867274                          51.3
[Warning: Failure at t=1.173280e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_KL_Kollam>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_KL_Kollam (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_KL_Kollam>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_KL_Kollam (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GJ_Mahisagar'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Mahisagar (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Mahisagar (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         56.7891                       7.2e+04
     1         12          3.2089       0.197239       3.34e+03      
[Warning: Failure at t=9.551111e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_GJ_Mahisagar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_GJ_Mahisagar (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_GJ_Mahisagar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_GJ_Mahisagar (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Panna'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Panna (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Panna (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Panna (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Jalore'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Jalore (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Jalore (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         7.16287                      9.02e+03
     1         12         1.11944        0.42911            262      
     2         18         1.11944       0.422203            262      
     3         24         1.11944       0.105551            262      
[Warning: Failure at t=1.062167e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_RJ_Jalore>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_RJ_Jalore (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_RJ_Jalore>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Jalore (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Shajapur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Shajapur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Shajapur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         352.075                      6.54e+05
     1         12        0.678996       0.407752            250      
     2         18        0.678996       0.277433            250      
     3         24        0.678996      0.0693583            250      
     4         30        0.353119      0.0173396            159      
     5         36        0.353119      0.0346791            159      
     6         42        0.337273     0.00866979           13.9      
     7         48        0.329141     0.00866979           7.78      
     8         54        0.292913     0.00866979           26.2      
     9         60         0.27732      0.0173396             15      
    10         66         0.27732      0.0173396             15      
    11         72        0.203084     0.00433489           11.4      
    12         78        0.184021     0.00433489           7.58      
    13         84        0.184021     0.00433489           7.58      
    14         90        0.169781     0.00108372           3.86      
    15         96        0.152291     0.00216745           3.43      
    16        102        0.143522     0.00433489           11.3      
    17        108        0.132118     0.00433489           4.41      
    18        114         0.12823     0.00433489           9.54      
    19        120        0.120389     0.00433489           4.45      
    20        126         0.11647     0.00433489           4.75      
    21        132        0.113785     0.00433489           3.33      
    22        138        0.112225     0.00433489           2.21      
    23        144        0.112135     0.00433489           2.07      
    24        150        0.111974     0.00108372           2.03      
    25        156        0.111822    0.000270931           1.39      
    26        162        0.111762    0.000270931           1.21      
    27        168        0.111656    6.77327e-05          0.279      
    28        174        0.111652    0.000135465           0.24      
    29        180        0.111648    0.000135465          0.236      
    30        186        0.111645    0.000135465          0.207      
    31        192        0.111642    0.000135465          0.193      
    32        198         0.11164    0.000135465          0.174      
    33        204        0.111638    0.000135465          0.158      
    34        210        0.111636    0.000135465          0.145      
    35        216        0.111635    0.000135465          0.129      
    36        222        0.111633    0.000135465          0.119      
    37        228        0.111632    0.000135465          0.103      
    38        234        0.111631    0.000135465         0.0952      
    39        240         0.11163    0.000135465         0.0791      
    40        246         0.11163    0.000135465         0.0726      
    41        252        0.111629    0.000135465         0.0483      
    42        258        0.111629    0.000135465         0.0411      
    43        264        0.111629    3.38664e-05         0.0332      
    44        270        0.111629    8.46659e-06         0.0261      
    45        276        0.111629    2.11665e-06        0.00249      
    46        282        0.111629    2.11665e-06        0.00223      
    47        288        0.111629    2.11665e-06        0.00221      
    48        294        0.111629    2.11665e-06        0.00203      
    49        300        0.111629    2.11665e-06        0.00197      
    50        306        0.111629    2.11665e-06        0.00184      
    51        312        0.111629    2.11665e-06        0.00177      
    52        318        0.111629    2.11665e-06        0.00167      
    53        324        0.111629    2.11665e-06        0.00161      
    54        330        0.111629    2.11665e-06        0.00151      
    55        336        0.111629    2.11665e-06        0.00146      
    56        342        0.111629    2.11665e-06        0.00138      
    57        348        0.111629    2.11665e-06        0.00132      
    58        354        0.111629    2.11665e-06        0.00125      
    59        360        0.111629    2.11665e-06         0.0012      
    60        366        0.111629    2.11665e-06        0.00113      
    61        372        0.111629    2.11665e-06        0.00109      
    62        378        0.111629    2.11665e-06        0.00103      
    63        384        0.111629    2.11665e-06       0.000995      
    64        390        0.111629    2.11665e-06       0.000935      
    65        396        0.111629    2.11665e-06       0.000902      
    66        402        0.111629    2.11665e-06       0.000842      
    67        408        0.111629    2.11665e-06        0.00081      
    68        414        0.111629    2.11665e-06       0.000755      
    69        420        0.111629    2.11665e-06       0.000727      
    70        426        0.111629    2.11665e-06       0.000676      
    71        432        0.111629    2.11665e-06       0.000652      
    72        438        0.111629    2.11665e-06       0.000603      
    73        444        0.111629    2.11665e-06       0.000581      
    74        450        0.111629    2.11665e-06       0.000535      
    75        456        0.111629    2.11665e-06       0.000515      
    76        462        0.111629    2.11665e-06       0.000471      
    77        468        0.111629    2.11665e-06       0.000454      
    78        474        0.111629    2.11665e-06       0.000408      
    79        480        0.111629    2.11665e-06       0.000393      
    80        486        0.111629    2.11665e-06       0.000343      
    81        492        0.111629    2.11665e-06        0.00033      
    82        498        0.111629    2.11665e-06       0.000267      
    83        504        0.111629    2.11665e-06       0.000279      
    84        510        0.111629    2.11665e-06       0.000224      
    85        516        0.111629    5.29162e-07       0.000184      
    86        522        0.111629    5.29162e-07       0.000184      
    87        528        0.111629     1.3229e-07       0.000184      
    88        534        0.111629    3.30726e-08       0.000184      
    89        540        0.111629    8.26815e-09       7.23e-05      
    90        546        0.111629    9.60642e-09       7.23e-05      
    91        552        0.111629    2.06704e-09       4.44e-05      
    92        558        0.111629    2.06704e-09       4.44e-05      
    93        564        0.111629     5.1676e-10       4.44e-05      
    94        570        0.111629     1.2919e-10       4.26e-05      
    95        576        0.111629    3.22975e-11       4.22e-05      
    96        582        0.111629    8.07437e-12       4.21e-05      
    97        588        0.111629    2.01859e-12       4.21e-05      
    98        594        0.111629    5.04648e-13       4.21e-05      
    99        600        0.111629    1.26162e-13       4.21e-05      
   100        606        0.111629    3.15405e-14       4.21e-05      
   101        612        0.111629    7.88512e-15       4.21e-05      
   102        618        0.111629    1.97128e-15       4.21e-05      

Local minimum possible.

lsqnonlin stopped because the final change in the sum of squares relative to 
its initial value is less than the value of the function tolerance.


kpar =

    0.1154
    0.0736
   -0.0120
    0.0033
   -0.0162


resnorm =

    0.1116

[Warning: Failure at t=3.020251e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (9.094947e-13)
at time t.] 
[> In ode15s (line 715)
  In optimize_MP_Shajapur (line 89)] 

kpar =

    0.1154
    0.0736
   -0.0120
    0.0033
   -0.0162


N =

     1512353

{Unrecognized function or variable 'err'.

Error in optimize_MP_Shajapur (line 100)
err
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'TN_Thoothukkudi'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_TN_Thoothukkudi (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_TN_Thoothukkudi (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         0.10412                          91.6
[Warning: Failure at t=5.426306e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_TN_Thoothukkudi>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_TN_Thoothukkudi (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_TN_Thoothukkudi>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_TN_Thoothukkudi (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'AR_Tawang'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Tawang (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Tawang (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.616002                          47.1
     1         12        0.616002        5.12363           47.1      
     2         18        0.616002        1.28091           47.1      
     3         24        0.547478       0.320227           7.32      
     4         30        0.547478       0.320227           7.32      
[Warning: Failure at t=1.562861e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_AR_Tawang>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_AR_Tawang (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_AR_Tawang>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_AR_Tawang (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'KL_Pathanamthitta'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KL_Pathanamthitta (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KL_Pathanamthitta (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.239982                          70.1
     1         12        0.239982       0.546916           70.1      
     2         18        0.239982       0.136729           70.1      
[Warning: Failure at t=1.260779e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_KL_Pathanamthitta>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_KL_Pathanamthitta (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_KL_Pathanamthitta>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_KL_Pathanamthitta (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'WB_Darjeeling'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_WB_Darjeeling (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_WB_Darjeeling (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6       0.0240191                          47.1
[Warning: Failure at t=1.680039e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_WB_Darjeeling>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_WB_Darjeeling (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_WB_Darjeeling>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_WB_Darjeeling (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Rajgarh'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Rajgarh (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Rajgarh (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         134.688                      1.36e+05
     1         12         134.688       0.527847       1.36e+05      
     2         18         28.5156       0.131962        5.4e+04      
     3         24        0.169867       0.263923           14.3      
     4         30        0.169867       0.603444           14.3      
[Warning: Failure at t=1.684143e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Rajgarh>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Rajgarh (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MP_Rajgarh>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Rajgarh (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'CT_Koriya'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Koriya (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Koriya (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         1.44117                      2.85e+03
[Warning: Failure at t=2.283603e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_CT_Koriya>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_CT_Koriya (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_CT_Koriya>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_CT_Koriya (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Alwar'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Alwar (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Alwar (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         5.46657                      7.08e+03
     1         12        0.478343       0.115204            819      
     2         18       0.0832457      0.0462321            109      
     3         24       0.0407535       0.192882           10.6      
[Warning: Failure at t=7.091926e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_RJ_Alwar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_RJ_Alwar (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_RJ_Alwar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Alwar (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Jabalpur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Jabalpur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Jabalpur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6       0.0958227                          20.3
[Warning: Failure at t=1.550461e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Jabalpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Jabalpur (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MP_Jabalpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Jabalpur (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Khandwa'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Khandwa (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Khandwa (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6          75.287                       7.1e+04
     1         12         1.66491        0.25424       1.05e+03      
[Warning: Failure at t=1.041401e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Khandwa>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Khandwa (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MP_Khandwa>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Khandwa (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Evacuees'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Evacuees (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Evacuees (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Evacuees (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Burhanpur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Burhanpur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Burhanpur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         6.52618                      9.56e+03
     1         12         1.02559       0.905552       6.98e+03      
[Warning: Failure at t=6.552946e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Burhanpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Burhanpur (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_MP_Burhanpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Burhanpur (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'BR_Jamui'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Jamui (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Jamui (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6          350.42                      3.83e+05
     1         12        0.323926       0.392862           8.74      
     2         18        0.323926       0.375875           8.74      
[Warning: Failure at t=1.751935e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_BR_Jamui>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_BR_Jamui (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_BR_Jamui>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_BR_Jamui (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'TN_Krishnagiri'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_TN_Krishnagiri (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_TN_Krishnagiri (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.968757                      1.38e+03
     1         12        0.952468       0.433598            273      
     2         18        0.952468         0.1084            273      
[Warning: Failure at t=7.935205e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_TN_Krishnagiri>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_TN_Krishnagiri (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_TN_Krishnagiri>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_TN_Krishnagiri (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GJ_Surat'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Surat (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Surat (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6      0.00769012                          7.77
     1         12      0.00769012       0.697198           7.77      
     2         18      0.00551842         0.1743            5.3      
     3         24      0.00425104         0.1743            2.4      
     4         30      0.00412345         0.1743          0.989      
     5         36      0.00390546      0.0435749           1.25      
     6         42      0.00390546      0.0435749           1.25      
     7         48      0.00383224      0.0108937            1.1      
     8         54       0.0038286     0.00272343           1.09      
     9         60         0.00377    0.000680858          0.862      
    10         66      0.00371832    0.000170214          0.556      
    11         72      0.00371001    0.000170214          0.496      
    12         78       0.0036822    4.25536e-05          0.139      
    13         84      0.00368179    8.51072e-05           0.15      
    14         90      0.00367899    2.12768e-05         0.0247      
    15         96      0.00367889    2.12768e-05         0.0774      
    16        102      0.00367824     5.3192e-06         0.0357      
    17        108      0.00367795    1.06384e-05         0.0351      
    18        114      0.00367767    1.06384e-05         0.0382      
    19        120       0.0036774    1.06384e-05         0.0359      
    20        126      0.00367716    1.06384e-05         0.0392      
    21        132      0.00367693    1.06384e-05         0.0368      
    22        138      0.00367671    1.06384e-05           0.04      
    23        144       0.0036765    1.06384e-05         0.0377      
    24        150      0.00367631    1.06384e-05         0.0406      
    25        156      0.00367628    1.27201e-05          0.054      
    26        162      0.00367602     2.6596e-06         0.0331      
    27        168      0.00367578     5.3192e-06         0.0145      
    28        174       0.0036756     5.3192e-06         0.0147      
    29        180      0.00367531    1.06384e-05         0.0236      
    30        186      0.00367528    2.12768e-05         0.0421      
    31        192        0.003675     5.3192e-06         0.0125      
    32        198      0.00367484     5.3192e-06         0.0117      
    33        204      0.00367457    1.06384e-05         0.0135      
    34        210      0.00367456    2.12768e-05         0.0393      
    35        216      0.00367434     5.3192e-06         0.0102      
    36        222      0.00367422     5.3192e-06        0.00914      
    37        228       0.0036742    1.06384e-05         0.0358      
    38        234      0.00367405     2.6596e-06         0.0146      
    39        240      0.00367402     5.3192e-06         0.0217      
    40        246      0.00367396     5.3192e-06         0.0181      
    41        252      0.00367392     5.3192e-06         0.0209      
    42        258      0.00367387     5.3192e-06          0.019      
    43        264      0.00367387    6.33219e-06         0.0285      
    44        270       0.0036738     1.3298e-06          0.018      
    45        276      0.00367375     2.6596e-06        0.00714      
    46        282       0.0036737     2.6596e-06        0.00648      
    47        288      0.00367364     5.3192e-06         0.0125      
    48        294      0.00367364    1.06384e-05         0.0224      
    49        300      0.00367357     2.6596e-06        0.00575      
    50        306      0.00367353     2.6596e-06        0.00567      
    51        312      0.00367347     5.3192e-06         0.0104      
    52        318      0.00367346    1.06384e-05         0.0163      
    53        324      0.00367342     2.6596e-06        0.00455      
    54        330       0.0036734     2.6596e-06        0.00826      
    55        336      0.00367339     2.6596e-06         0.0102      
    56        342      0.00367338     2.6596e-06        0.00913      
    57        348      0.00367336     2.6596e-06         0.0102      
    58        354      0.00367335     2.6596e-06        0.00943      
    59        360      0.00367334     2.6596e-06         0.0102      
    60        366      0.00367334    3.14898e-06         0.0134      
    61        372      0.00367332      6.649e-07        0.00817      
    62        378      0.00367331     1.3298e-06        0.00342      
    63        384       0.0036733     1.3298e-06         0.0035      
    64        390      0.00367328     2.6596e-06        0.00697      
    65        396      0.00367328     2.6596e-06         0.0097      
    66        402      0.00367327      6.649e-07        0.00453      
    67        408      0.00367326     1.3298e-06        0.00414      
    68        414      0.00367325     1.3298e-06        0.00393      
    69        420      0.00367325     1.3298e-06        0.00448      
    70        426      0.00367324     1.3298e-06         0.0041      
    71        432      0.00367324     1.3298e-06        0.00462      
    72        438      0.00367323     1.3298e-06        0.00427      
    73        444      0.00367323     1.3298e-06        0.00475      
    74        450      0.00367322     1.3298e-06         0.0044      
    75        456      0.00367322     1.3298e-06        0.00485      
    76        462      0.00367321     1.3298e-06        0.00451      
    77        468      0.00367321     1.3298e-06        0.00504      
    78        474      0.00367321     1.3298e-06        0.00454      
    79        480       0.0036732     1.3298e-06        0.00502      
    80        486       0.0036732     1.3298e-06        0.00464      
    81        492       0.0036732     1.3298e-06        0.00504      
    82        498       0.0036732    1.55167e-06        0.00662      
    83        504      0.00367319     3.3245e-07        0.00399      
    84        510      0.00367319      6.649e-07         0.0016      
    85        516      0.00367319      6.649e-07        0.00165      
    86        522      0.00367318     1.3298e-06        0.00383      
    87        528      0.00367318     1.3298e-06        0.00457      
    88        534      0.00367318     3.3245e-07          0.002      
    89        540      0.00367318      6.649e-07         0.0021      
    90        546      0.00367318      6.649e-07        0.00198      
    91        552      0.00367317      6.649e-07        0.00226      
    92        558      0.00367317      6.649e-07          0.002      
    93        564      0.00367317      6.649e-07        0.00227      
    94        570      0.00367317      6.649e-07        0.00207      
    95        576      0.00367317      6.649e-07        0.00232      
    96        582      0.00367317      6.649e-07        0.00212      
    97        588      0.00367317      6.649e-07        0.00235      
    98        594      0.00367317      6.649e-07        0.00215      
    99        600      0.00367317      6.649e-07        0.00237      
   100        606      0.00367316      6.649e-07        0.00216      
   101        612      0.00367316      6.649e-07        0.00237      
   102        618      0.00367316     7.8678e-07        0.00338      
   103        624      0.00367316    1.66225e-07        0.00208      
   104        630      0.00367316     3.3245e-07       0.000808      
   105        636      0.00367316     3.3245e-07       0.000822      
   106        642      0.00367316      6.649e-07        0.00135      
   107        648      0.00367316     1.3298e-06        0.00245      
   108        654      0.00367316     1.3298e-06         0.0033      
   109        660      0.00367316     3.3245e-07       0.000665      
   110        666      0.00367316      6.649e-07        0.00192      
   111        672      0.00367316      6.649e-07        0.00215      
   112        678      0.00367316      6.649e-07        0.00198      
   113        684      0.00367315      6.649e-07        0.00211      
   114        690      0.00367315      6.649e-07        0.00194      
   115        696      0.00367315      6.649e-07        0.00205      
   116        702      0.00367315      6.649e-07        0.00188      
   117        708      0.00367315      6.649e-07        0.00198      
   118        714      0.00367315      6.649e-07        0.00182      
   119        720      0.00367315      6.649e-07        0.00191      
   120        726      0.00367315      6.649e-07        0.00175      
   121        732      0.00367315      6.649e-07        0.00184      
   122        738      0.00367315      6.649e-07        0.00169      
   123        744      0.00367315      6.649e-07        0.00217      
   124        750      0.00367315    1.66225e-07       0.000844      
   125        756      0.00367315     3.3245e-07       0.000899      
   126        762      0.00367315    3.79132e-07        0.00175      
   127        768      0.00367315    8.31125e-08        0.00109      
   128        774      0.00367315    1.66225e-07       0.000474      
   129        780      0.00367315    1.66225e-07       0.000442      
   130        786      0.00367315     3.3245e-07       0.000715      
   131        792      0.00367315      6.649e-07        0.00117      
   132        798      0.00367315      6.649e-07        0.00118      
   133        804      0.00367315      6.649e-07        0.00131      
   134        810      0.00367315      6.649e-07        0.00124      
   135        816      0.00367315      6.649e-07        0.00131      
   136        822      0.00367315      6.649e-07        0.00122      
   137        828      0.00367315      6.649e-07        0.00127      
   138        834      0.00367315      6.649e-07        0.00118      
   139        840      0.00367315      6.649e-07        0.00122      
   140        846      0.00367315      6.649e-07        0.00113      
   141        852      0.00367315      6.649e-07        0.00117      
   142        858      0.00367314      6.649e-07        0.00108      
   143        864      0.00367314      6.649e-07        0.00112      
   144        870      0.00367314      6.649e-07        0.00104      
   145        876      0.00367314      6.649e-07        0.00108      
   146        882      0.00367314      6.649e-07       0.000998      
   147        888      0.00367314      6.649e-07        0.00103      
   148        894      0.00367314      6.649e-07       0.000958      
   149        900      0.00367314      6.649e-07       0.000991      
   150        906      0.00367314      6.649e-07       0.000922      
   151        912      0.00367314      6.649e-07       0.000953      
   152        918      0.00367314      6.649e-07       0.000888      
   153        924      0.00367314      6.649e-07       0.000918      
   154        930      0.00367314      6.649e-07       0.000856      
   155        936      0.00367314      6.649e-07       0.000885      
   156        942      0.00367314      6.649e-07       0.000827      
   157        948      0.00367314      6.649e-07       0.000855      
   158        954      0.00367314      6.649e-07         0.0008      
   159        960      0.00367314      6.649e-07       0.000827      
   160        966      0.00367314      6.649e-07       0.000775      
   161        972      0.00367314      6.649e-07       0.000801      
   162        978      0.00367314      6.649e-07       0.000752      
   163        984      0.00367314      6.649e-07       0.000777      
   164        990      0.00367314      6.649e-07       0.000731      
   165        996      0.00367314      6.649e-07       0.000756      
   166       1002      0.00367314      6.649e-07       0.000712      
   167       1008      0.00367314      6.649e-07       0.000736      
   168       1014      0.00367314      6.649e-07       0.000695      
   169       1020      0.00367314      6.649e-07       0.000718      
   170       1026      0.00367314      6.649e-07       0.000679      
   171       1032      0.00367314      6.649e-07       0.000701      
   172       1038      0.00367314     1.3298e-06       0.000783      
   173       1044      0.00367313     2.6596e-06       0.000864      
   174       1050      0.00367313     5.3192e-06       0.000914      
   175       1056      0.00367313    1.06384e-05       0.000991      
   176       1062      0.00367312    2.12768e-05        0.00103      
   177       1068       0.0036731    4.25536e-05        0.00109      
   178       1074      0.00367306    8.51072e-05        0.00116      
   179       1080      0.00367299    0.000170214        0.00119      
   180       1086      0.00367284    0.000340429        0.00154      
   181       1092      0.00367257    0.000680858        0.00176      
   182       1098      0.00367204     0.00136172         0.0038      
   183       1104      0.00367114     0.00272343        0.00484      
   184       1110      0.00366987     0.00544686         0.0158      
   185       1116      0.00366886      0.0108937         0.0124      
   186       1122      0.00366886      0.0108937         0.0124      
   187       1128      0.00366848     0.00272343          0.016      
   188       1134      0.00366832     0.00272343         0.0141      
   189       1140      0.00366812     0.00272343         0.0153      
   190       1146      0.00366812    0.000518849         0.0153      
   191       1152      0.00366811    0.000129712         0.0192      
   192       1158      0.00366811     3.2428e-05          0.019      
   193       1164      0.00366811    8.10701e-06         0.0187      
   194       1170      0.00366808    2.02675e-06        0.00117      
   195       1176      0.00366808    2.02675e-06        0.00124      
   196       1182      0.00366808    5.06688e-07        0.00124      
   197       1188      0.00366808    1.26672e-07       0.000191      
   198       1194      0.00366808    1.26672e-07       0.000164      
   199       1200      0.00366808    2.03765e-07       0.000878      
   200       1206      0.00366808    5.09412e-08       0.000393      
   201       1212      0.00366808    1.21805e-07       0.000393      
   202       1218      0.00366808    2.54706e-08       0.000173      
   203       1224      0.00366808    5.09412e-08       0.000152      
   204       1230      0.00366808    5.09412e-08       0.000157      
   205       1236      0.00366808    1.01882e-07       0.000422      
   206       1242      0.00366808    1.11361e-07       0.000565      
   207       1248      0.00366808    2.54706e-08       0.000327      
   208       1254      0.00366808    5.09412e-08       0.000131      
   209       1260      0.00366808    5.09412e-08       0.000141      
   210       1266      0.00366808    1.01882e-07       0.000473      
   211       1272      0.00366808    2.54706e-08       0.000238      
   212       1278      0.00366808    5.09412e-08       0.000164      
   213       1284      0.00366808    9.31343e-08       0.000164      
   214       1290      0.00366808    2.32836e-08       0.000124      
   215       1296      0.00366808    2.32836e-08       0.000121      
   216       1302      0.00366808    4.65671e-08       0.000118      
   217       1308      0.00366807    9.31343e-08       0.000109      
   218       1314      0.00366807    1.86269e-07       0.000345      
   219       1320      0.00366807    3.72537e-07       0.000345      
   220       1326      0.00366807    8.44547e-08       0.000345      
   221       1332      0.00366807    2.11137e-08       0.000149      
   222       1338      0.00366807    4.22273e-08        0.00018      
   223       1344      0.00366807    4.22273e-08       0.000164      
   224       1350      0.00366807    4.22273e-08        0.00018      
   225       1356      0.00366807    1.05568e-08        9.3e-05      
   226       1362      0.00366807    2.11137e-08       9.29e-05      
   227       1368      0.00366807    4.22273e-08       0.000114      
   228       1374      0.00366807    4.22273e-08       0.000185      
   229       1380      0.00366807    4.22273e-08       0.000182      
   230       1386      0.00366807    1.05568e-08       9.13e-05      
   231       1392      0.00366807    2.11137e-08       8.57e-05      
   232       1398      0.00366807    4.22273e-08       0.000149      
   233       1404      0.00366807    4.76739e-08       0.000246      
   234       1410      0.00366807    4.22273e-08       0.000144      
   235       1416      0.00366807    4.55909e-08       0.000235      
   236       1422      0.00366807    4.22273e-08       0.000155      
   237       1428      0.00366807    1.05568e-08       7.13e-05      
   238       1434      0.00366807    2.11137e-08       7.69e-05      
   239       1440      0.00366807    4.22273e-08       0.000189      
   240       1446      0.00366807    1.05568e-08       9.33e-05      
   241       1452      0.00366807    2.11137e-08       7.39e-05      
   242       1458      0.00366807    4.78864e-08       7.39e-05      
   243       1464      0.00366807    1.05568e-08       6.95e-05      
   244       1470      0.00366807    1.05568e-08        6.9e-05      
   245       1476      0.00366807    2.11137e-08       6.75e-05      
   246       1482      0.00366807    4.22273e-08       6.52e-05      
   247       1488      0.00366807    8.44547e-08       5.68e-05      
   248       1494      0.00366807    1.68909e-07       0.000182      
   249       1500      0.00366807    3.37819e-07       0.000225      
   250       1506      0.00366807    8.44547e-08       0.000244      
   251       1512      0.00366807    8.44547e-08       0.000244      
   252       1518      0.00366807    2.11137e-08       5.89e-05      
   253       1524      0.00366807    2.11137e-08       8.53e-05      
   254       1530      0.00366807    5.27842e-09       5.31e-05      
   255       1536      0.00366807    1.05568e-08        5.6e-05      
   256       1542      0.00366807    2.11137e-08       5.25e-05      
   257       1548      0.00366807    2.11137e-08       8.75e-05      
   258       1554      0.00366807    4.22273e-08       8.75e-05      
   259       1560      0.00366807    1.05568e-08       5.28e-05      
   260       1566      0.00366807    1.05568e-08       5.22e-05      
   261       1572      0.00366807    2.11137e-08       5.14e-05      
   262       1578      0.00366807    4.22273e-08       4.82e-05      
   263       1584      0.00366807    7.65811e-08       0.000255      
   264       1590      0.00366807    8.44547e-08       0.000255      
   265       1596      0.00366807    2.11137e-08        5.1e-05      
   266       1602      0.00366807    2.11137e-08        5.1e-05      
   267       1608      0.00366807    5.27842e-09       4.68e-05      
   268       1614      0.00366807    5.27842e-09       4.58e-05      
   269       1620      0.00366807    1.05568e-08       4.55e-05      
   270       1626      0.00366807    2.11137e-08       4.45e-05      
   271       1632      0.00366807    4.22273e-08       4.49e-05      
   272       1638      0.00366807    8.44547e-08       4.49e-05      
   273       1644      0.00366807    2.11137e-08        8.3e-05      
   274       1650      0.00366807    5.27842e-09       4.07e-05      
   275       1656      0.00366807    1.05568e-08       4.42e-05      
   276       1662      0.00366807    2.11137e-08       8.62e-05      
   277       1668      0.00366807    5.27842e-09       4.02e-05      
   278       1674      0.00366807    1.05568e-08       4.35e-05      
   279       1680      0.00366807    2.11137e-08       8.79e-05      
   280       1686      0.00366807    5.27842e-09       4.16e-05      
   281       1692      0.00366807    1.05568e-08       4.28e-05      
   282       1698      0.00366807    2.11137e-08       8.52e-05      
   283       1704      0.00366807    5.27842e-09       3.92e-05      
   284       1710      0.00366807    1.05568e-08       4.22e-05      
   285       1716      0.00366807    2.11137e-08       4.22e-05      
   286       1722      0.00366807    5.27842e-09       4.04e-05      
   287       1728      0.00366807    5.27842e-09       4.02e-05      
   288       1734      0.00366807    1.05568e-08          4e-05      
   289       1740      0.00366807    2.11137e-08       3.96e-05      
   290       1746      0.00366807    4.22273e-08       3.91e-05      
   291       1752      0.00366807    8.44547e-08       9.81e-05      
   292       1758      0.00366807    1.68909e-07       0.000129      
   293       1764      0.00366807    3.37819e-07       0.000155      
   294       1770      0.00366807    8.44547e-08       0.000172      
   295       1776      0.00366807    8.44547e-08       0.000172      
   296       1782      0.00366807    2.11137e-08       3.53e-05      
   297       1788      0.00366807    2.11137e-08       8.76e-05      
   298       1794      0.00366807    4.22273e-08       8.76e-05      
   299       1800      0.00366807    1.05568e-08       3.63e-05      
   300       1806      0.00366807    1.05568e-08       3.69e-05      
   301       1812      0.00366807    2.11137e-08       3.46e-05      
   302       1818      0.00366807    4.22273e-08       0.000139      
   303       1824      0.00366807    8.44547e-08       0.000139      
   304       1830      0.00366807    2.11137e-08       5.99e-05      
   305       1836      0.00366807    5.27842e-09        3.5e-05      
   306       1842      0.00366807    1.05568e-08       3.71e-05      
   307       1848      0.00366807    2.11137e-08       7.59e-05      
   308       1854      0.00366807    5.27842e-09        3.4e-05      
   309       1860      0.00366807    1.05568e-08       3.74e-05      
   310       1866      0.00366807    2.11137e-08       3.74e-05      
   311       1872      0.00366807    5.27842e-09       3.56e-05      
   312       1878      0.00366807    5.27842e-09       3.56e-05      
   313       1884      0.00366807    1.05568e-08       3.55e-05      
   314       1890      0.00366807    2.11137e-08       3.54e-05      
   315       1896      0.00366807    4.22273e-08       3.49e-05      
   316       1902      0.00366807    8.44547e-08       4.02e-05      
   317       1908      0.00366807    1.68909e-07       0.000122      
   318       1914      0.00366807    4.22273e-08       0.000146      
   319       1920      0.00366807    4.22273e-08       0.000146      
   320       1926      0.00366807    1.05568e-08       4.59e-05      
   321       1932      0.00366807    1.05568e-08       3.26e-05      
   322       1938      0.00366807    2.63921e-09       3.35e-05      
   323       1944      0.00366807    5.27842e-09       3.45e-05      
   324       1950      0.00366807    1.05568e-08       3.41e-05      
   325       1956      0.00366807    2.11137e-08       3.52e-05      
   326       1962      0.00366807    4.22273e-08       3.52e-05      
   327       1968      0.00366807    1.05568e-08       3.29e-05      
   328       1974      0.00366807    1.05568e-08       3.57e-05      
   329       1980      0.00366807    2.11137e-08       3.57e-05      
   330       1986      0.00366807    5.27842e-09       3.41e-05      
   331       1992      0.00366807    5.27842e-09       3.41e-05      
   332       1998      0.00366807    1.05568e-08       3.41e-05      
   333       2004      0.00366807    2.11137e-08       3.42e-05      
   334       2010      0.00366807    4.22273e-08       3.28e-05      
   335       2016      0.00366807    8.44547e-08       0.000166      
   336       2022      0.00366807    1.68909e-07       0.000166      
   337       2028      0.00366807    3.66762e-08       0.000166      
   338       2034      0.00366807    9.16906e-09       7.83e-05      
   339       2040      0.00366807    9.16906e-09       3.37e-05      
   340       2046      0.00366807    9.16906e-09       3.38e-05      
   341       2052      0.00366807    1.83381e-08       3.35e-05      
   342       2058      0.00366807    3.66762e-08       3.55e-05      
   343       2064      0.00366807    7.33525e-08       3.55e-05      
   344       2070      0.00366807    1.83381e-08       3.55e-05      
   345       2076      0.00366807    4.58453e-09       3.39e-05      
   346       2082      0.00366807    4.58453e-09       3.36e-05      
   347       2088      0.00366807    9.16906e-09       3.36e-05      
   348       2094      0.00366807    1.83381e-08       3.34e-05      
   349       2100      0.00366807    3.66762e-08       3.43e-05      
   350       2106      0.00366807     7.5418e-08       3.43e-05      
   351       2112      0.00366807    1.83381e-08       4.67e-05      
   352       2118      0.00366807    2.18779e-08       0.000115      
   353       2124      0.00366807    3.66762e-08       0.000115      
   354       2130      0.00366807    9.16906e-09       3.52e-05      
   355       2136      0.00366807    9.16906e-09       3.21e-05      
   356       2142      0.00366807    9.16906e-09       3.46e-05      
   357       2148      0.00366807    1.83381e-08       6.12e-05      
   358       2154      0.00366807    2.14248e-08       0.000113      
   359       2160      0.00366807    3.66762e-08       0.000113      
   360       2166      0.00366807    9.16906e-09        3.5e-05      
   361       2172      0.00366807    9.16906e-09       3.21e-05      
   362       2178      0.00366807    9.16906e-09       3.45e-05      
   363       2184      0.00366807    1.83381e-08       6.11e-05      
   364       2190      0.00366807    2.14073e-08       0.000113      
   365       2196      0.00366807    3.66762e-08       0.000113      
   366       2202      0.00366807    9.16906e-09       3.49e-05      
   367       2208      0.00366807    9.16906e-09        3.2e-05      
   368       2214      0.00366807    9.16906e-09       3.45e-05      
   369       2220      0.00366807    1.83381e-08       6.13e-05      
   370       2226      0.00366807    2.13937e-08       0.000113      
   371       2232      0.00366807    3.66762e-08       0.000113      
   372       2238      0.00366807    9.16906e-09       3.49e-05      
   373       2244      0.00366807    9.16906e-09       3.19e-05      
   374       2250      0.00366807    9.16906e-09       3.44e-05      
   375       2256      0.00366807    1.83381e-08       6.14e-05      
   376       2262      0.00366807    2.13803e-08       0.000113      
   377       2268      0.00366807    3.66762e-08       0.000113      
   378       2274      0.00366807    9.16906e-09       3.48e-05      
   379       2280      0.00366807    9.16906e-09       3.19e-05      
   380       2286      0.00366807    9.16906e-09       3.44e-05      
   381       2292      0.00366807    1.83381e-08       6.18e-05      
   382       2298      0.00366807    2.13755e-08       0.000113      
   383       2304      0.00366807    3.66762e-08       0.000113      
   384       2310      0.00366807    9.16906e-09       3.48e-05      
   385       2316      0.00366807    9.16906e-09       3.18e-05      
   386       2322      0.00366807    9.16906e-09       3.43e-05      
   387       2328      0.00366807    1.83381e-08       6.19e-05      
   388       2334      0.00366807    2.13631e-08       0.000113      
   389       2340      0.00366807    3.66762e-08       0.000113      
   390       2346      0.00366807    9.16906e-09       3.47e-05      
   391       2352      0.00366807    9.16906e-09       3.18e-05      
   392       2358      0.00366807    9.16906e-09       3.43e-05      
   393       2364      0.00366807    1.83381e-08        6.2e-05      
   394       2370      0.00366807    2.13505e-08       0.000113      
   395       2376      0.00366807    3.66762e-08       0.000113      
   396       2382      0.00366807    9.16906e-09       3.47e-05      
   397       2388      0.00366807    9.16906e-09       3.17e-05      
   398       2394      0.00366807    9.16906e-09       3.42e-05      
   399       2400      0.00366807    1.83381e-08       6.19e-05      
   400       2406      0.00366807    2.13296e-08       0.000113      
   401       2412      0.00366807    3.66762e-08       0.000113      
   402       2418      0.00366807    9.16906e-09       3.46e-05      
   403       2424      0.00366807    9.16906e-09       3.17e-05      
   404       2430      0.00366807    9.16906e-09       3.42e-05      
   405       2436      0.00366807    1.83381e-08       6.18e-05      
   406       2442      0.00366807    2.13121e-08       0.000113      
   407       2448      0.00366807    3.66762e-08       0.000113      
   408       2454      0.00366807    9.16906e-09       3.46e-05      
   409       2460      0.00366807    9.16906e-09       3.16e-05      
   410       2466      0.00366807    9.16906e-09       3.42e-05      
   411       2472      0.00366807    1.83381e-08       6.21e-05      
   412       2478      0.00366807    2.13048e-08       0.000113      
   413       2484      0.00366807    3.66762e-08       0.000113      
   414       2490      0.00366807    9.16906e-09       3.45e-05      
   415       2496      0.00366807    9.16906e-09       3.16e-05      
   416       2502      0.00366807    9.16906e-09       3.41e-05      
   417       2508      0.00366807    1.83381e-08       6.25e-05      
   418       2514      0.00366807    4.58453e-09       3.15e-05      
   419       2520      0.00366807    9.16906e-09       3.41e-05      
   420       2526      0.00366807    1.83381e-08       6.33e-05      
   421       2532      0.00366807    4.58453e-09       3.15e-05      
   422       2538      0.00366807    9.16906e-09       3.41e-05      
   423       2544      0.00366807    1.83381e-08       6.38e-05      
   424       2550      0.00366807    4.58453e-09       3.14e-05      
   425       2556      0.00366807    9.16906e-09       3.41e-05      
   426       2562      0.00366807    1.83381e-08       6.37e-05      
   427       2568      0.00366807    4.58453e-09       3.14e-05      
   428       2574      0.00366807    9.16906e-09       3.41e-05      
   429       2580      0.00366807    1.83381e-08       6.42e-05      
   430       2586      0.00366807    4.58453e-09       3.14e-05      
   431       2592      0.00366807    9.16906e-09       3.41e-05      
   432       2598      0.00366807    1.83381e-08       6.59e-05      
   433       2604      0.00366807    4.58453e-09       3.13e-05      
   434       2610      0.00366807    9.16906e-09       3.41e-05      
   435       2616      0.00366807    1.83381e-08       6.53e-05      
   436       2622      0.00366807    4.58453e-09       3.13e-05      
   437       2628      0.00366807    9.16906e-09       3.41e-05      
   438       2634      0.00366807    1.83381e-08       6.51e-05      
   439       2640      0.00366807    4.58453e-09       3.13e-05      
   440       2646      0.00366807    9.16906e-09        3.4e-05      
   441       2652      0.00366807    1.83381e-08        6.6e-05      
   442       2658      0.00366807    4.58453e-09       3.12e-05      
   443       2664      0.00366807    9.16906e-09        3.4e-05      
   444       2670      0.00366807    1.83381e-08       6.65e-05      
   445       2676      0.00366807    4.58453e-09       3.12e-05      
   446       2682      0.00366807    9.16906e-09        3.4e-05      
   447       2688      0.00366807    1.83381e-08       6.67e-05      
   448       2694      0.00366807    4.58453e-09       3.11e-05      
   449       2700      0.00366807    9.16906e-09        3.4e-05      
   450       2706      0.00366807    1.83381e-08       6.59e-05      
   451       2712      0.00366807    4.58453e-09       3.12e-05      
   452       2718      0.00366807    9.16906e-09        3.4e-05      
   453       2724      0.00366807    1.83381e-08       6.51e-05      
   454       2730      0.00366807    4.58453e-09       3.12e-05      
   455       2736      0.00366807    9.16906e-09       3.39e-05      
   456       2742      0.00366807    1.83381e-08       6.48e-05      
   457       2748      0.00366807    4.58453e-09       3.12e-05      
   458       2754      0.00366807    9.16906e-09       3.39e-05      
   459       2760      0.00366807    1.83381e-08       6.52e-05      
   460       2766      0.00366807    4.58453e-09       3.11e-05      
   461       2772      0.00366807    9.16906e-09       3.39e-05      
   462       2778      0.00366807    1.83381e-08       6.71e-05      
   463       2784      0.00366807    4.58453e-09        3.1e-05      
   464       2790      0.00366807    9.16906e-09       3.39e-05      
   465       2796      0.00366807    1.83381e-08       6.62e-05      
   466       2802      0.00366807    4.58453e-09       3.11e-05      
   467       2808      0.00366807    9.16906e-09       3.39e-05      
   468       2814      0.00366807    1.83381e-08        6.6e-05      
   469       2820      0.00366807    4.58453e-09        3.1e-05      
   470       2826      0.00366807    9.16906e-09       3.39e-05      
   471       2832      0.00366807    1.83381e-08        6.6e-05      
   472       2838      0.00366807    4.58453e-09        3.1e-05      
   473       2844      0.00366807    9.16906e-09       3.39e-05      
   474       2850      0.00366807    1.83381e-08       6.77e-05      
   475       2856      0.00366807    4.58453e-09       3.09e-05      
   476       2862      0.00366807    9.16906e-09       3.39e-05      
   477       2868      0.00366807    1.83381e-08       6.66e-05      
   478       2874      0.00366807    4.58453e-09        3.1e-05      
   479       2880      0.00366807    9.16906e-09       3.39e-05      
   480       2886      0.00366807    1.83381e-08       6.64e-05      
   481       2892      0.00366807    4.58453e-09        3.1e-05      
   482       2898      0.00366807    9.16906e-09       3.38e-05      
   483       2904      0.00366807    1.83381e-08       6.58e-05      
   484       2910      0.00366807    4.58453e-09        3.1e-05      
   485       2916      0.00366807    9.16906e-09       3.38e-05      
   486       2922      0.00366807    1.83381e-08       6.72e-05      
   487       2928      0.00366807    4.58453e-09       3.09e-05      
   488       2934      0.00366807    9.16906e-09       3.38e-05      
   489       2940      0.00366807    1.83381e-08       6.62e-05      
   490       2946      0.00366807    4.58453e-09       3.09e-05      
   491       2952      0.00366807    9.16906e-09       3.38e-05      
   492       2958      0.00366807    1.83381e-08       6.75e-05      
   493       2964      0.00366807    4.58453e-09       3.08e-05      
   494       2970      0.00366807    9.16906e-09       3.38e-05      
   495       2976      0.00366807    1.83381e-08       6.69e-05      
   496       2982      0.00366807    4.58453e-09       3.09e-05      
   497       2988      0.00366807    9.16906e-09       3.37e-05      
   498       2994      0.00366807    1.83381e-08       6.63e-05      
   499       3000      0.00366807    4.58453e-09       3.09e-05      
   500       3006      0.00366807    9.16906e-09       3.37e-05      
   501       3012      0.00366807    1.83381e-08       6.83e-05      
   502       3018      0.00366807    4.58453e-09       3.08e-05      
   503       3024      0.00366807    9.16906e-09       3.37e-05      
   504       3030      0.00366807    1.83381e-08       6.91e-05      
   505       3036      0.00366807    4.58453e-09       3.07e-05      
   506       3042      0.00366807    9.16906e-09       3.37e-05      
   507       3048      0.00366807    1.83381e-08       6.94e-05      
   508       3054      0.00366807    4.58453e-09       3.07e-05      
   509       3060      0.00366807    9.16906e-09       3.37e-05      
   510       3066      0.00366807    1.83381e-08       6.95e-05      
   511       3072      0.00366807    4.58453e-09       3.07e-05      
   512       3078      0.00366807    9.16906e-09       3.37e-05      
   513       3084      0.00366807    1.83381e-08       6.96e-05      
   514       3090      0.00366807    4.58453e-09       3.06e-05      
   515       3096      0.00366807    9.16906e-09       3.37e-05      
   516       3102      0.00366807    1.83381e-08       6.97e-05      
   517       3108      0.00366807    4.58453e-09       3.07e-05      
   518       3114      0.00366807    9.16906e-09       3.37e-05      
   519       3120      0.00366807    1.83381e-08       6.98e-05      
   520       3126      0.00366807    4.58453e-09       3.08e-05      
   521       3132      0.00366807    9.16906e-09       3.37e-05      
   522       3138      0.00366807    1.83381e-08       6.99e-05      
   523       3144      0.00366807    4.58453e-09       3.08e-05      
   524       3150      0.00366807    9.16906e-09       3.37e-05      
   525       3156      0.00366807    1.83381e-08          7e-05      
   526       3162      0.00366807    4.58453e-09       3.09e-05      
   527       3168      0.00366807    9.16906e-09       3.36e-05      
   528       3174      0.00366807    1.83381e-08          7e-05      
   529       3180      0.00366807    4.58453e-09       3.09e-05      
   530       3186      0.00366807    9.16906e-09       3.36e-05      
   531       3192      0.00366807    1.83381e-08       7.01e-05      
   532       3198      0.00366807    4.58453e-09        3.1e-05      
   533       3204      0.00366807    9.16906e-09       3.36e-05      
   534       3210      0.00366807    1.83381e-08       7.02e-05      
   535       3216      0.00366807    4.58453e-09       3.11e-05      
   536       3222      0.00366807    9.16906e-09       3.36e-05      
   537       3228      0.00366807    1.83381e-08       7.03e-05      
   538       3234      0.00366807    4.58453e-09       3.11e-05      
   539       3240      0.00366807    9.16906e-09       3.36e-05      
   540       3246      0.00366807    1.83381e-08       7.03e-05      
   541       3252      0.00366807    4.58453e-09       3.12e-05      
   542       3258      0.00366807    9.16906e-09       3.36e-05      
   543       3264      0.00366807    1.83381e-08       7.04e-05      
   544       3270      0.00366807    4.58453e-09       3.12e-05      
   545       3276      0.00366807    9.16906e-09       3.36e-05      
   546       3282      0.00366807    1.83381e-08       7.05e-05      
   547       3288      0.00366807    4.58453e-09       3.13e-05      
   548       3294      0.00366807    9.16906e-09       3.35e-05      
   549       3300      0.00366807    1.83381e-08       7.05e-05      
   550       3306      0.00366807    4.58453e-09       3.14e-05      
   551       3312      0.00366807    9.16906e-09       3.35e-05      
   552       3318      0.00366807    1.83381e-08       7.06e-05      
   553       3324      0.00366807    4.58453e-09       3.14e-05      
   554       3330      0.00366807    9.16906e-09       3.35e-05      
   555       3336      0.00366807    1.83381e-08       7.07e-05      
   556       3342      0.00366807    4.58453e-09       3.15e-05      
   557       3348      0.00366807    9.16906e-09       3.35e-05      
   558       3354      0.00366807    1.83381e-08       7.08e-05      
   559       3360      0.00366807    4.58453e-09       3.15e-05      
   560       3366      0.00366807    9.16906e-09       3.35e-05      
   561       3372      0.00366807    1.83381e-08       7.08e-05      
   562       3378      0.00366807    4.58453e-09       3.16e-05      
   563       3384      0.00366807    9.16906e-09       3.35e-05      
   564       3390      0.00366807    1.83381e-08       7.09e-05      
   565       3396      0.00366807    4.58453e-09       3.16e-05      
   566       3402      0.00366807    9.16906e-09       3.35e-05      
   567       3408      0.00366807    1.83381e-08        7.1e-05      
   568       3414      0.00366807    4.58453e-09       3.17e-05      
   569       3420      0.00366807    9.16906e-09       3.34e-05      
   570       3426      0.00366807    1.83381e-08        7.1e-05      
   571       3432      0.00366807    4.58453e-09       3.18e-05      
   572       3438      0.00366807    9.16906e-09       3.34e-05      
   573       3444      0.00366807    1.83381e-08       7.11e-05      
   574       3450      0.00366807    4.58453e-09       3.18e-05      
   575       3456      0.00366807    9.16906e-09       3.34e-05      
   576       3462      0.00366807    1.83381e-08       7.12e-05      
   577       3468      0.00366807    4.58453e-09       3.19e-05      
   578       3474      0.00366807    9.16906e-09       3.34e-05      
   579       3480      0.00366807    1.83381e-08       7.13e-05      
   580       3486      0.00366807    4.58453e-09       3.19e-05      
   581       3492      0.00366807    9.16906e-09       3.34e-05      
   582       3498      0.00366807    1.83381e-08       7.13e-05      
   583       3504      0.00366807    4.58453e-09        3.2e-05      
   584       3510      0.00366807    9.16906e-09       3.34e-05      
   585       3516      0.00366807    1.83381e-08       7.14e-05      
   586       3522      0.00366807    4.58453e-09        3.2e-05      
   587       3528      0.00366807    9.16906e-09       3.34e-05      
   588       3534      0.00366807    1.83381e-08       7.15e-05      
   589       3540      0.00366807    4.58453e-09       3.21e-05      
   590       3546      0.00366807    9.16906e-09       3.33e-05      
   591       3552      0.00366807    1.83381e-08       7.15e-05      
   592       3558      0.00366807    4.58453e-09       3.22e-05      
   593       3564      0.00366807    9.16906e-09       3.33e-05      
   594       3570      0.00366807    1.83381e-08       7.16e-05      
   595       3576      0.00366807    4.58453e-09       3.22e-05      
   596       3582      0.00366807    9.16906e-09       3.33e-05      
   597       3588      0.00366807    1.83381e-08       7.17e-05      
   598       3594      0.00366807    4.58453e-09       3.23e-05      
   599       3600      0.00366807    9.16906e-09       3.33e-05      
   600       3606      0.00366807    1.83381e-08       7.17e-05      
   601       3612      0.00366807    4.58453e-09       3.23e-05      
   602       3618      0.00366807    9.16906e-09       3.33e-05      
   603       3624      0.00366807    1.83381e-08       7.18e-05      
   604       3630      0.00366807    4.58453e-09       3.24e-05      
   605       3636      0.00366807    9.16906e-09       3.33e-05      
   606       3642      0.00366807    1.83381e-08       7.19e-05      
   607       3648      0.00366807    4.58453e-09       3.24e-05      
   608       3654      0.00366807    9.16906e-09       3.33e-05      
   609       3660      0.00366807    1.83381e-08       7.19e-05      
   610       3666      0.00366807    4.58453e-09       3.25e-05      
   611       3672      0.00366807    9.16906e-09       3.33e-05      
   612       3678      0.00366807    1.83381e-08        7.2e-05      
   613       3684      0.00366807    4.58453e-09       3.25e-05      
   614       3690      0.00366807    9.16906e-09       3.32e-05      
   615       3696      0.00366807    1.83381e-08       7.21e-05      
   616       3702      0.00366807    4.58453e-09       3.26e-05      
   617       3708      0.00366807    9.16906e-09       3.32e-05      
   618       3714      0.00366807    1.83381e-08       7.21e-05      
   619       3720      0.00366807    4.58453e-09       3.26e-05      
   620       3726      0.00366807    9.16906e-09       3.32e-05      
   621       3732      0.00366807    1.83381e-08       7.22e-05      
   622       3738      0.00366807    4.58453e-09       3.27e-05      
   623       3744      0.00366807    9.16906e-09       3.32e-05      
   624       3750      0.00366807    1.83381e-08       7.23e-05      
   625       3756      0.00366807    4.58453e-09       3.27e-05      
   626       3762      0.00366807    9.16906e-09       3.32e-05      
   627       3768      0.00366807    1.83381e-08       7.23e-05      
   628       3774      0.00366807    4.58453e-09       3.28e-05      
   629       3780      0.00366807    9.16906e-09       3.32e-05      
   630       3786      0.00366807    1.83381e-08       7.24e-05      
   631       3792      0.00366807    4.58453e-09       3.29e-05      
   632       3798      0.00366807    9.16906e-09       3.32e-05      
   633       3804      0.00366807    1.83381e-08       7.25e-05      
   634       3810      0.00366807    4.58453e-09       3.29e-05      
   635       3816      0.00366807    9.16906e-09       3.31e-05      
   636       3822      0.00366807    1.83381e-08       3.31e-05      
   637       3828      0.00366807    4.58453e-09       3.18e-05      
   638       3834      0.00366807    4.58453e-09       3.17e-05      
   639       3840      0.00366807    9.16906e-09       3.17e-05      
   640       3846      0.00366807    1.83381e-08       3.17e-05      
   641       3852      0.00366807    3.66762e-08       3.19e-05      
   642       3858      0.00366807    7.33525e-08       7.79e-05      
   643       3864      0.00366807    1.46705e-07       0.000114      
   644       3870      0.00366807     2.9341e-07       0.000138      
   645       3876      0.00366807    7.33525e-08       0.000156      
   646       3882      0.00366807    7.33525e-08       0.000156      
   647       3888      0.00366807    1.83381e-08       3.06e-05      
   648       3894      0.00366807    1.83381e-08       5.62e-05      
   649       3900      0.00366807    3.66762e-08       5.62e-05      
   650       3906      0.00366807    9.16906e-09       3.05e-05      
   651       3912      0.00366807    2.29226e-09       3.11e-05      
   652       3918      0.00366807    4.58453e-09       3.16e-05      
   653       3924      0.00366807    9.16906e-09       3.14e-05      
   654       3930      0.00366807    1.83381e-08       3.18e-05      
   655       3936      0.00366807    3.66762e-08       4.27e-05      
   656       3942      0.00366807    7.33525e-08       0.000107      
   657       3948      0.00366807    1.46705e-07       0.000107      
   658       3954      0.00366807    3.66762e-08       0.000107      
   659       3960      0.00366807    9.16906e-09       3.28e-05      
   660       3966      0.00366807    9.16906e-09       3.02e-05      
   661       3972      0.00366807    9.16906e-09       3.28e-05      
   662       3978      0.00366807    1.83381e-08       6.86e-05      
   663       3984      0.00366807    4.58453e-09       2.98e-05      
   664       3990      0.00366807    9.16906e-09       3.29e-05      
   665       3996      0.00366807    1.83381e-08       3.29e-05      
   666       4002      0.00366807    4.58453e-09       3.15e-05      
   667       4008      0.00366807    4.58453e-09       3.15e-05      
   668       4014      0.00366807    9.16906e-09       3.15e-05      
   669       4020      0.00366807    1.83381e-08       3.14e-05      
   670       4026      0.00366807    3.66762e-08       3.16e-05      
   671       4032      0.00366807    7.33525e-08        6.6e-05      
   672       4038      0.00366807    1.46705e-07       0.000108      
   673       4044      0.00366807     2.9341e-07       0.000134      
   674       4050      0.00366807    7.33525e-08       0.000152      
   675       4056      0.00366807    7.33525e-08       0.000152      
   676       4062      0.00366807    1.83381e-08       3.01e-05      
   677       4068      0.00366807    1.83381e-08       6.51e-05      
   678       4074      0.00366807    3.66762e-08       6.51e-05      
   679       4080      0.00366807    9.16906e-09       3.06e-05      
   680       4086      0.00366807    2.29226e-09        3.1e-05      
   681       4092      0.00366807    4.58453e-09       3.13e-05      
   682       4098      0.00366807    9.16906e-09       3.12e-05      
   683       4104      0.00366807    1.83381e-08       3.15e-05      
   684       4110      0.00366807    3.66762e-08       3.33e-05      
   685       4116      0.00366807    7.33525e-08       0.000115      
   686       4122      0.00366807    1.46705e-07       0.000115      
   687       4128      0.00366807    3.66762e-08       0.000115      
   688       4134      0.00366807    9.16906e-09        3.3e-05      
   689       4140      0.00366807    9.16906e-09       2.98e-05      
   690       4146      0.00366807    2.29226e-09       3.05e-05      
   691       4152      0.00366807    4.58453e-09       3.13e-05      
   692       4158      0.00366807    9.16906e-09       3.11e-05      
   693       4164      0.00366807    1.83381e-08       3.16e-05      
   694       4170      0.00366807    3.66762e-08       5.51e-05      
   695       4176      0.00366807    3.66762e-08        9.9e-05      
   696       4182      0.00366807    7.33525e-08        9.9e-05      
   697       4188      0.00366807    1.83381e-08        9.9e-05      
   698       4194      0.00366807    4.58453e-09       5.71e-05      
   699       4200      0.00366807    4.58453e-09       3.23e-05      
   700       4206      0.00366807    4.58453e-09       3.12e-05      
   701       4212      0.00366807    4.58453e-09       3.12e-05      
   702       4218      0.00366807    9.16906e-09       3.12e-05      
   703       4224      0.00366807    1.83381e-08       3.12e-05      
   704       4230      0.00366807    3.66762e-08       3.09e-05      
   705       4236      0.00366807    7.33525e-08       8.71e-05      
   706       4242      0.00366807    1.46705e-07       8.71e-05      
   707       4248      0.00366807    3.66762e-08       8.71e-05      
   708       4254      0.00366807    9.16906e-09       3.14e-05      
   709       4260      0.00366807    9.16906e-09       3.07e-05      
   710       4266      0.00366807    1.83381e-08       3.25e-05      
   711       4272      0.00366807    3.66762e-08       3.25e-05      
   712       4278      0.00366807    9.16906e-09       2.98e-05      
   713       4284      0.00366807    9.16906e-09       3.25e-05      
   714       4290      0.00366807    1.83381e-08       7.15e-05      
   715       4296      0.00366807    4.58453e-09       3.19e-05      
   716       4302      0.00366807    9.16906e-09       3.25e-05      
   717       4308      0.00366807    1.83381e-08       3.25e-05      
   718       4314      0.00366807    4.58453e-09       3.11e-05      
   719       4320      0.00366807    4.58453e-09       3.11e-05      
   720       4326      0.00366807    9.16906e-09       3.11e-05      
   721       4332      0.00366807    1.83381e-08       3.11e-05      
   722       4338      0.00366807    3.66762e-08       3.13e-05      
   723       4344      0.00366807    7.33525e-08       7.98e-05      
   724       4350      0.00366807    1.46705e-07       0.000112      
   725       4356      0.00366807     2.9341e-07       0.000136      
   726       4362      0.00366807    7.33525e-08        0.00015      
   727       4368      0.00366807    7.33525e-08        0.00015      
   728       4374      0.00366807    1.83381e-08       2.96e-05      
   729       4380      0.00366807    1.83381e-08       7.11e-05      
   730       4386      0.00366807    3.66762e-08       7.11e-05      
   731       4392      0.00366807    9.16906e-09       3.05e-05      
   732       4398      0.00366807    2.29226e-09       3.07e-05      
   733       4404      0.00366807    4.58453e-09        3.1e-05      
   734       4410      0.00366807    9.16906e-09       3.09e-05      
   735       4416      0.00366807    1.83381e-08       3.11e-05      
   736       4422      0.00366807    3.66762e-08       2.95e-05      
   737       4428      0.00366807    7.33525e-08       0.000139      
   738       4434      0.00366807    1.46705e-07       0.000139      
   739       4440      0.00366807    3.66762e-08       0.000139      
   740       4446      0.00366807    9.16906e-09       5.21e-05      
   741       4452      0.00366807    9.16906e-09       2.97e-05      
   742       4458      0.00366807    2.29226e-09       3.03e-05      
   743       4464      0.00366807    4.58453e-09       3.09e-05      
   744       4470      0.00366807    9.16906e-09       3.08e-05      
   745       4476      0.00366807    1.83381e-08       3.13e-05      
   746       4482      0.00366807    3.66762e-08       5.91e-05      
   747       4488      0.00366807    3.66762e-08       0.000105      
   748       4494      0.00366807    7.33525e-08       0.000105      
   749       4500      0.00366807    1.83381e-08       0.000105      
   750       4506      0.00366807    4.58453e-09        6.3e-05      
   751       4512      0.00366807    4.58453e-09       3.22e-05      
   752       4518      0.00366807    4.58453e-09       3.08e-05      
   753       4524      0.00366807    4.58453e-09       3.08e-05      
   754       4530      0.00366807    9.16906e-09       3.08e-05      
   755       4536      0.00366807    1.83381e-08       3.08e-05      
   756       4542      0.00366807    3.66762e-08       3.09e-05      
   757       4548      0.00366807    7.33525e-08       3.48e-05      
   758       4554      0.00366807    1.46705e-07       0.000113      
   759       4560      0.00366807     2.9341e-07       0.000137      
   760       4566      0.00366807    7.33525e-08        0.00015      
   761       4572      0.00366807    7.33525e-08        0.00015      
   762       4578      0.00366807    1.83381e-08       2.93e-05      
   763       4584      0.00366807    1.83381e-08       7.18e-05      
   764       4590      0.00366807    3.66762e-08       7.18e-05      
   765       4596      0.00366807    9.16906e-09       3.02e-05      
   766       4602      0.00366807    2.29226e-09       3.05e-05      
   767       4608      0.00366807    4.58453e-09       3.07e-05      
   768       4614      0.00366807    9.16906e-09       3.06e-05      
   769       4620      0.00366807    1.83381e-08       3.08e-05      
   770       4626      0.00366807    3.66762e-08       2.92e-05      
   771       4632      0.00366807    7.33525e-08       0.000135      
   772       4638      0.00366807    1.46705e-07       0.000135      
   773       4644      0.00366807    3.05615e-08       0.000135      
   774       4650      0.00366807    7.64036e-09       6.25e-05      
   775       4656      0.00366807    7.64036e-09       3.05e-05      
   776       4662      0.00366807    1.91009e-09       3.06e-05      
   777       4668      0.00366807    3.82018e-09       3.06e-05      
   778       4674      0.00366807    7.64036e-09       3.06e-05      
   779       4680      0.00366807    1.52807e-08       3.06e-05      
   780       4686      0.00366807    3.05615e-08       3.06e-05      
   781       4692      0.00366807    6.11229e-08       3.05e-05      
   782       4698      0.00366807    1.22246e-07       4.76e-05      
   783       4704      0.00366807    2.44492e-07       0.000105      
   784       4710      0.00366807    2.44492e-07       0.000127      
   785       4716      0.00366807    4.88983e-07       0.000147      
   786       4722      0.00366807    4.88983e-07       0.000162      
   787       4728      0.00366807    4.88983e-07       0.000176      
   788       4734      0.00366807    1.22246e-07       0.000186      
   789       4740      0.00366807    1.22246e-07       0.000186      
   790       4746      0.00366807    3.05615e-08       0.000107      
   791       4752      0.00366807    7.64036e-09       3.64e-05      
   792       4758      0.00366807    1.52807e-08       6.74e-05      
   793       4764      0.00366807    3.05615e-08       6.74e-05      
   794       4770      0.00366807    7.64036e-09       3.03e-05      
   795       4776      0.00366807    7.64036e-09       3.01e-05      
   796       4782      0.00366807    1.52807e-08       3.05e-05      
   797       4788      0.00366807    3.05615e-08       4.47e-05      
   798       4794      0.00366807    6.11229e-08       0.000101      
   799       4800      0.00366807    1.22246e-07       0.000101      
   800       4806      0.00366807    2.47937e-08       0.000101      
   801       4812      0.00366807    6.19843e-09       4.38e-05      
   802       4818      0.00366807    6.19843e-09          3e-05      
   803       4824      0.00366807    1.54961e-09       3.01e-05      
   804       4830      0.00366807    3.09922e-09       3.02e-05      
   805       4836      0.00366807    6.19843e-09       3.02e-05      
   806       4842      0.00366807    1.23969e-08       3.01e-05      
   807       4848      0.00366807    2.47937e-08       3.03e-05      
   808       4854      0.00366807    4.95875e-08       2.89e-05      
   809       4860      0.00366807     9.9175e-08       0.000135      
   810       4866      0.00366807     1.9835e-07       0.000135      
   811       4872      0.00366807    4.95875e-08       0.000135      
   812       4878      0.00366807    1.23969e-08       3.12e-05      
   813       4884      0.00366807    1.23969e-08       3.59e-05      
   814       4890      0.00366807    1.23969e-08       4.79e-05      
   815       4896      0.00366807    2.47937e-08       4.79e-05      
   816       4902      0.00366807    6.19843e-09       3.02e-05      
   817       4908      0.00366807    1.54961e-09       3.02e-05      
   818       4914      0.00366807    3.09922e-09       3.02e-05      
   819       4920      0.00366807    6.19843e-09       3.02e-05      
   820       4926      0.00366807    1.23969e-08       3.02e-05      
   821       4932      0.00366807    2.47937e-08       3.01e-05      
   822       4938      0.00366807    4.95875e-08       3.02e-05      
   823       4944      0.00366807     9.9175e-08       4.88e-05      
   824       4950      0.00366807     1.9835e-07       0.000102      
   825       4956      0.00366807      3.967e-07       0.000127      
   826       4962      0.00366807      3.967e-07       0.000144      
   827       4968      0.00366807      7.934e-07       0.000162      
   828       4974      0.00366807      7.934e-07       0.000175      
   829       4980      0.00366807     1.5868e-06       0.000189      
   830       4986      0.00366807     1.5868e-06       0.000198      
   831       4992      0.00366807     3.1736e-06       0.000211      
   832       4998      0.00366807     3.1736e-06       0.000219      
   833       5004      0.00366807     6.3472e-06       0.000233      
   834       5010      0.00366807    1.26944e-05       0.000232      
   835       5016      0.00366807    2.53888e-05       0.000266      
   836       5022      0.00366807    5.07776e-05       0.000254      
   837       5028      0.00366807    0.000101555       0.000396      
   838       5034      0.00366807     0.00017567       0.000396      
   839       5040      0.00366807    4.39174e-05       0.000632      
   840       5046      0.00366807    4.39174e-05       0.000688      
   841       5052      0.00366807    4.39174e-05       0.000729      
   842       5058      0.00366807    4.39174e-05       0.000837      
   843       5064      0.00366807    1.09794e-05       0.000958      
   844       5070      0.00366807    2.74484e-06       0.000958      
   845       5076      0.00366807     6.8621e-07       0.000958      
   846       5082      0.00366807     1.9287e-07       0.000958      
   847       5088      0.00366807    4.28881e-08       0.000537      
   848       5094      0.00366807    8.57762e-08       0.000299      
   849       5100      0.00366807    8.57762e-08       0.000318      
   850       5106      0.00366807    2.14441e-08       0.000108      
   851       5112      0.00366807    2.30776e-08       0.000108      
   852       5118      0.00366807    5.36101e-09       5.74e-05      
   853       5124      0.00366807    5.36101e-09       2.38e-05      
   854       5130      0.00366807    1.34025e-09       2.13e-05      
   855       5136      0.00366807    3.35063e-10       2.07e-05      
   856       5142      0.00366807    3.35063e-10       2.01e-05      
   857       5148      0.00366807    3.35063e-10       1.95e-05      
   858       5154      0.00366807    3.35063e-10        1.9e-05      
   859       5160      0.00366807    3.35063e-10       1.84e-05      
   860       5166      0.00366807    3.35063e-10       1.79e-05      
   861       5172      0.00366807    3.35063e-10       1.74e-05      
   862       5178      0.00366807    3.35063e-10       1.69e-05      
   863       5184      0.00366807    3.35063e-10       1.64e-05      
   864       5190      0.00366807    3.35063e-10       1.59e-05      
   865       5196      0.00366807    3.35063e-10       1.54e-05      
   866       5202      0.00366807    3.35063e-10       1.49e-05      
   867       5208      0.00366807    6.70127e-10       1.39e-05      
   868       5214      0.00366807    1.34025e-09        1.2e-05      
   869       5220      0.00366807    1.34025e-09       1.03e-05      
   870       5226      0.00366807    2.68051e-09       6.95e-06      
   871       5232      0.00366807    2.68051e-09       6.02e-06      
   872       5238      0.00366807    2.68051e-09       6.03e-06      
   873       5244      0.00366807    2.68051e-09       5.88e-06      
   874       5250      0.00366807    2.68051e-09       5.65e-06      
   875       5256      0.00366807    2.68051e-09       5.39e-06      
   876       5262      0.00366807    2.68051e-09       5.12e-06      
   877       5268      0.00366807    2.68051e-09       4.87e-06      
   878       5274      0.00366807    6.70127e-10       4.77e-06      
   879       5280      0.00366807    1.34025e-09       4.66e-06      
   880       5286      0.00366807    3.35063e-10       4.61e-06      
   881       5292      0.00366807    3.35063e-10       4.58e-06      
   882       5298      0.00366807    3.35063e-10       4.54e-06      
   883       5304      0.00366807    3.35063e-10       4.51e-06      
   884       5310      0.00366807    3.35063e-10       4.48e-06      
   885       5316      0.00366807    3.35063e-10       4.44e-06      
   886       5322      0.00366807    8.37658e-11       4.44e-06      
   887       5328      0.00366807    2.09415e-11       4.43e-06      
   888       5334      0.00366807    2.09415e-11       4.43e-06      
   889       5340      0.00366807    5.23536e-12       4.43e-06      
   890       5346      0.00366807    1.30884e-12       4.43e-06      
   891       5352      0.00366807    1.30884e-12       4.43e-06      
   892       5358      0.00366807    1.30884e-12       4.43e-06      
   893       5364      0.00366807     3.2721e-13       4.43e-06      
   894       5370      0.00366807     3.2721e-13       4.43e-06      
   895       5376      0.00366807    8.18026e-14       4.43e-06      
   896       5382      0.00366807    2.04506e-14       4.43e-06      

Local minimum possible.

lsqnonlin stopped because the final change in the sum of squares relative to 
its initial value is less than the value of the function tolerance.


kpar =

    0.0939
    0.1183
    0.2986
    0.0027
    0.0012


resnorm =

    0.0037


kpar =

    0.0939
    0.1183
    0.2986
    0.0027
    0.0012


N =

     4996391

{Unrecognized function or variable 'err'.

Error in optimize_GJ_Surat (line 100)
err
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'HR_Gurugram'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_HR_Gurugram (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_HR_Gurugram (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.153024                            24
[Warning: Failure at t=6.974386e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_HR_Gurugram>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_HR_Gurugram (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_HR_Gurugram>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_HR_Gurugram (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'AR_Upper_Dibang_Valley'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Upper_Dibang_Valley (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Upper_Dibang_Valley (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_AR_Upper_Dibang_Valley (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'AR_Lohit'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Lohit (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Lohit (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_AR_Lohit (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'WB_Cooch_Behar'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_WB_Cooch_Behar (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_WB_Cooch_Behar (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         2.65289                      2.31e+03
     1         12       0.0269915       0.277393           9.61      
[Warning: Failure at t=1.396660e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_WB_Cooch_Behar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_WB_Cooch_Behar (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_WB_Cooch_Behar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_WB_Cooch_Behar (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MH_Parbhani'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Parbhani (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MH_Parbhani (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.420529                           352
[Warning: Failure at t=1.013653e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MH_Parbhani>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MH_Parbhani (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MH_Parbhani>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MH_Parbhani (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'KA_Bengaluru_Rural'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KA_Bengaluru_Rural (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_KA_Bengaluru_Rural (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         0.12094                          83.7
[Warning: Failure at t=1.930749e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_KA_Bengaluru_Rural>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_KA_Bengaluru_Rural (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_KA_Bengaluru_Rural>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_KA_Bengaluru_Rural (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'JK_Samba'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JK_Samba (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JK_Samba (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.799951                      1.65e+03
[Warning: Failure at t=3.498980e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_JK_Samba>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_JK_Samba (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_JK_Samba>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_JK_Samba (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Bhilwara'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Bhilwara (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Bhilwara (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         20.9357                      2.91e+04
     1         12         20.9357       0.545052       2.91e+04      
     2         18         4.03188       0.136263       5.61e+03      
     3         24        0.318378       0.123515            314      
[Warning: Failure at t=8.160044e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_RJ_Bhilwara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_RJ_Bhilwara (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_RJ_Bhilwara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Bhilwara (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'BR_Madhubani'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Madhubani (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Madhubani (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         60.8771                      3.84e+04
     1         12         4.78594       0.286787       1.61e+04      
[Warning: Failure at t=1.540028e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (4.547474e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_BR_Madhubani>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_BR_Madhubani (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_BR_Madhubani>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_BR_Madhubani (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GJ_Kutch'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Kutch (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Kutch (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         283.683                      2.93e+05
     1         12         15.3725       0.194763       1.44e+04      
     2         18         2.01814      0.0327839       2.52e+03      
     3         24        0.293308      0.0591145            180      
     4         30        0.152811      0.0904821           56.9      
     5         36        0.152811        1.08078           56.9      
     6         42        0.152811       0.270194           56.9      
     7         48        0.143025      0.0675485           40.5      
     8         54        0.143025      0.0675485           40.5      
     9         60        0.138574      0.0168871           15.1      
    10         66        0.137713      0.0168871           13.6      
    11         72        0.137713      0.0168871           13.6      
    12         78        0.137258     0.00422178           7.61      
    13         84         0.13712     0.00422178           6.78      
    14         90        0.137012     0.00105545           4.24      
    15         96        0.136973     0.00105545           3.46      
    16        102        0.136944     0.00105545           2.34      
    17        108         0.13693     0.00105545           1.79      
    18        114        0.136921     0.00105545            1.3      
    19        120        0.136916     0.00105545          0.949      
    20        126        0.136912     0.00105545           0.75      
    21        132         0.13691     0.00105545          0.536      
    22        138         0.13691     0.00105545           0.49      
    23        144        0.136909    0.000263861          0.373      
    24        150        0.136909    0.000263861          0.273      
    25        156        0.136909    0.000263861          0.219      
    26        162        0.136908    6.59653e-05          0.161      
    27        168        0.136908    6.59653e-05          0.119      
    28        174        0.136908    6.59653e-05         0.0898      
    29        180        0.136908    1.64913e-05         0.0652      
    30        186        0.136908    1.64913e-05         0.0456      
    31        192        0.136908    1.64913e-05         0.0339      
    32        198        0.136908    1.64913e-05         0.0234      
    33        204        0.136908    1.64913e-05         0.0179      
    34        210        0.136908    1.64913e-05         0.0123      
    35        216        0.136908    1.64913e-05        0.00986      
    36        222        0.136908    1.64913e-05        0.00694      
    37        228        0.136908    1.64913e-05        0.00613      
    38        234        0.136908    1.64913e-05         0.0057      
    39        240        0.136908    4.12283e-06        0.00454      
    40        246        0.136908    4.12283e-06        0.00275      
    41        252        0.136908    1.03071e-06        0.00218      
    42        258        0.136908    1.03071e-06        0.00218      
    43        264        0.136908    2.57677e-07        0.00218      
    44        270        0.136908    6.44193e-08        0.00218      
    45        276        0.136908    1.45955e-08        0.00218      
    46        282        0.136908    3.64887e-09        0.00126      
    47        288        0.136908    3.64887e-09       0.000341      
    48        294        0.136908    9.12217e-10       0.000341      
    49        300        0.136908    2.28054e-10       0.000341      
    50        306        0.136908    5.70135e-11       0.000341      
    51        312        0.136908    1.42534e-11       0.000341      
    52        318        0.136908    3.56335e-12       0.000341      
    53        324        0.136908    8.90837e-13       0.000341      
    54        330        0.136908    2.22709e-13       0.000341      
    55        336        0.136908    5.56773e-14       0.000341      
    56        342        0.136908    1.39193e-14       0.000341      
    57        348        0.136908    3.47983e-15       0.000341      
    58        354        0.136908    8.69958e-16       0.000341      
    59        360        0.136908    2.17489e-16       0.000341      
    60        366        0.136908    5.43724e-17       0.000341      

Local minimum possible.
lsqnonlin stopped because the size of the current step is less than
the value of the step size tolerance.


kpar =

    0.0926
    0.0955
    0.0723
    0.0007
    0.0017


resnorm =

    0.1369


kpar =

    0.0926
    0.0955
    0.0723
    0.0007
    0.0017


N =

     2090313

{Unrecognized function or variable 'err'.

Error in optimize_GJ_Kutch (line 100)
err
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'JH_Godda'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JH_Godda (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JH_Godda (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         157.885                      1.86e+05
[Warning: Failure at t=7.287731e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_JH_Godda>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_JH_Godda (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_JH_Godda>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_JH_Godda (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GJ_Mehsana'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Mehsana (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Mehsana (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6          33.673                      4.73e+04
     1         12         0.53758       0.242334            575      
[Warning: Failure at t=1.091410e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_GJ_Mehsana>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_GJ_Mehsana (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_GJ_Mehsana>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_GJ_Mehsana (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'UP_Amroha'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Amroha (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Amroha (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         15.7972                      1.27e+04
     1         12         15.7972       0.681186       1.27e+04      
     2         18         4.44126       0.170297       2.51e+03      
     3         24         0.21799       0.129519           32.8      
     4         30       0.0802617       0.143053             33      
     5         36       0.0802617       0.340593             33      
     6         42       0.0753734      0.0851483           7.22      
     7         48       0.0727954      0.0851483           10.9      
     8         54       0.0708327      0.0212871           7.96      
     9         60       0.0673604     0.00532177           2.58      
    10         66       0.0666801     0.00532177           2.49      
    11         72       0.0658851     0.00532177           1.35      
    12         78       0.0652888     0.00532177           1.25      
    13         84       0.0646843     0.00532177          0.982      
    14         90       0.0637079      0.0106435          0.742      
    15         96       0.0628237      0.0106435          0.955      
    16        102       0.0627097      0.0106435          0.278      
    17        108       0.0626508     0.00266088          0.235      
    18        114       0.0626163     0.00266088          0.157      
    19        120       0.0625947     0.00266088          0.199      
    20        126       0.0625779     0.00266088          0.229      
    21        132       0.0625779     0.00106236          0.229      
    22        138       0.0625768    0.000265591          0.185      
    23        144       0.0625755    6.63978e-05          0.122      
    24        150       0.0625747    6.63978e-05         0.0928      
    25        156       0.0625743    6.63978e-05         0.0606      
    26        162        0.062574    6.63978e-05         0.0414      
    27        168       0.0625739    6.63978e-05         0.0294      
    28        174       0.0625739    6.63978e-05         0.0194      
    29        180       0.0625738    6.63978e-05         0.0158      
    30        186       0.0625738    6.63978e-05         0.0101      
    31        192       0.0625738    6.63978e-05        0.00837      
    32        198       0.0625738    6.63978e-05        0.00837      
    33        204       0.0625738    1.65994e-05        0.00593      
    34        210       0.0625738    1.65994e-05        0.00436      
    35        216       0.0625738    4.33116e-06        0.00336      
    36        222       0.0625738    1.08279e-06         0.0024      
    37        228       0.0625738    1.08279e-06        0.00186      
    38        234       0.0625738    1.08279e-06        0.00124      
    39        240       0.0625738    1.08279e-06       0.000919      
    40        246       0.0625738    1.08279e-06       0.000638      
    41        252       0.0625738    1.08279e-06       0.000511      
    42        258       0.0625738    1.08279e-06       0.000359      
    43        264       0.0625738    1.08279e-06       0.000319      
    44        270       0.0625738    1.08279e-06       0.000217      
    45        276       0.0625738    4.96469e-07       0.000217      
    46        282       0.0625738    1.24117e-07       0.000159      
    47        288       0.0625738    2.48234e-07       0.000159      
    48        294       0.0625738    6.20586e-08       0.000159      
    49        300       0.0625738     1.7544e-08       0.000159      
    50        306       0.0625738    3.87866e-09       0.000101      
    51        312       0.0625738    3.87866e-09       4.38e-05      
    52        318       0.0625738    3.87866e-09       4.38e-05      
    53        324       0.0625738    9.69666e-10       4.38e-05      
    54        330       0.0625738    2.42416e-10       4.38e-05      
    55        336       0.0625738    6.06041e-11        4.3e-05      
    56        342       0.0625738     1.5151e-11        4.3e-05      
    57        348       0.0625738    3.78776e-12        4.3e-05      
    58        354       0.0625738    9.46939e-13        4.3e-05      
    59        360       0.0625738    2.36735e-13        4.3e-05      
    60        366       0.0625738    5.91837e-14        4.3e-05      
    61        372       0.0625738    1.47959e-14        4.3e-05      
    62        378       0.0625738    3.69898e-15        4.3e-05      
    63        384       0.0625738    9.24745e-16        4.3e-05      
    64        390       0.0625738    2.31186e-16        4.3e-05      
    65        396       0.0625738    5.77966e-17        4.3e-05      

Local minimum possible.
lsqnonlin stopped because the size of the current step is less than
the value of the step size tolerance.


kpar =

    0.0958
    0.1323
    0.0372
    0.0020
    0.0025


resnorm =

    0.0626


kpar =

    0.0958
    0.1323
    0.0372
    0.0020
    0.0025


N =

     1838771

{Unrecognized function or variable 'err'.

Error in optimize_UP_Amroha (line 100)
err
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Banswara'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Banswara (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Banswara (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         233.515                      2.72e+05
     1         12         1.04755       0.412681            366      
     2         18         1.04755       0.435628            366      
     3         24         1.04755       0.108907            366      
[Warning: Failure at t=1.237712e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_RJ_Banswara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_RJ_Banswara (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_RJ_Banswara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Banswara (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'BR_Muzaffarpur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Muzaffarpur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_BR_Muzaffarpur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         41.5696                      2.44e+04
     1         12         4.13415       0.274213       4.35e+03      
     2         18        0.337702       0.285804            160      
     3         24       0.0736156       0.218932             19      
[Warning: Failure at t=4.674403e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_BR_Muzaffarpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_BR_Muzaffarpur (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_BR_Muzaffarpur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_BR_Muzaffarpur (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'AR_Anjaw'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Anjaw (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_AR_Anjaw (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_AR_Anjaw (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'RJ_Ajmer'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Ajmer (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_RJ_Ajmer (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.460267                           633
     1         12        0.062698      0.0691667           95.7      
[Warning: Failure at t=9.299632e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_RJ_Ajmer>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_RJ_Ajmer (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_RJ_Ajmer>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_RJ_Ajmer (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'CT_Raigarh'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Raigarh (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Raigarh (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.271414                          16.8
     1         12        0.271414        4.81181           16.8      
     2         18        0.271414        1.20295           16.8      
[Warning: Failure at t=7.720492e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_CT_Raigarh>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_CT_Raigarh (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_CT_Raigarh>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_CT_Raigarh (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'OR_State_Pool'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_OR_State_Pool (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_OR_State_Pool (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_OR_State_Pool (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MP_Indore'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Indore (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MP_Indore (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.082713                          51.7
     1         12        0.082713       0.951947           51.7      
     2         18       0.0317069       0.237987           7.08      
[Warning: Failure at t=5.326095e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_MP_Indore>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_MP_Indore (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_MP_Indore>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MP_Indore (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'HR_Fatehabad'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_HR_Fatehabad (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_HR_Fatehabad (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.768839                      1.58e+03
[Warning: Failure at t=7.388468e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_HR_Fatehabad>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_HR_Fatehabad (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_HR_Fatehabad>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_HR_Fatehabad (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'OR_Jharsuguda'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_OR_Jharsuguda (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_OR_Jharsuguda (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.312067                           566
[Warning: Failure at t=6.307991e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.136868e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_OR_Jharsuguda>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_OR_Jharsuguda (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_OR_Jharsuguda>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line
73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_OR_Jharsuguda (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'MZ_Champhai'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MZ_Champhai (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_MZ_Champhai (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_MZ_Champhai (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'JK_Kishtwar'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JK_Kishtwar (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JK_Kishtwar (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         2.13071                       4.7e+03
[Warning: Failure at t=5.217102e+00.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (1.421085e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_JK_Kishtwar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_JK_Kishtwar (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_JK_Kishtwar>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_JK_Kishtwar (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'JK_Kupwara'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JK_Kupwara (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JK_Kupwara (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.396095                           777
[Warning: Failure at t=2.592420e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_JK_Kupwara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_JK_Kupwara (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_JK_Kupwara>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_JK_Kupwara (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'OR_Nabarangapur'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_OR_Nabarangapur (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_OR_Nabarangapur (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         6.77259                      7.26e+03
     1         12        0.316461        0.20436            168      
[Warning: Failure at t=2.570679e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_OR_Nabarangapur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_OR_Nabarangapur (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_OR_Nabarangapur>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_OR_Nabarangapur (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'UP_Bijnor'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Bijnor (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_UP_Bijnor (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6          132.74                       8.9e+04
     1         12         1.10905       0.292135            401      
[Warning: Failure at t=8.476386e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_UP_Bijnor>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_UP_Bijnor (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_UP_Bijnor>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_UP_Bijnor (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'JH_Ramgarh'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JH_Ramgarh (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_JH_Ramgarh (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6         1.90724                      2.36e+03
[Warning: Failure at t=1.119830e+02.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (2.273737e-13)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_JH_Ramgarh>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_JH_Ramgarh (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in optimize_JH_Ramgarh>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_JH_Ramgarh (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

[Warning: Unable to load Toolbox Path Cache
/home/rajat/.matlab/R2020a/toolbox_cache-9.8.0-2264267968-glnxa64.xml. The
cache file is not in the correct format. It will be regenerated upon quitting
MATLAB.] 
 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'GJ_Other_State'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Other_State (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_GJ_Other_State (line 59)] 
{Error using snls (line 47)
Objective function is returning undefined values at initial point. lsqnonlin
cannot continue.

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_GJ_Other_State (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
                  R2020a (9.8.0.1323502) 64-bit (glnxa64)
                             February 25, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 

state =

    'CT_Uttar_Bastar_Kanker'

[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Uttar_Bastar_Kanker (line 58)] 
[Warning: Polynomial is badly conditioned. Add points with distinct X values,
reduce the degree of the polynomial, or try centering and scaling as described
in HELP POLYFIT.] 
[> In polyfit (line 72)
  In optimize_CT_Uttar_Bastar_Kanker (line 59)] 

                                         Norm of      First-order 
 Iteration  Func-count     f(x)          step          optimality
     0          6        0.380959                           354
[Warning: Failure at t=3.077900e+01.  Unable to meet integration tolerances
without reducing the step size below the smallest value allowed (5.684342e-14)
at time t.] 
[> In ode45 (line 360)
  In integrate (line 14)
  In optimize_CT_Uttar_Bastar_Kanker>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly) (line 73)
  In snls (line 342)
  In lsqncommon (line 164)
  In lsqnonlin (line 262)
  In optimize_CT_Uttar_Bastar_Kanker (line 73)] 
{Matrix dimensions must agree.

Error in integrate (line 19)
err = (ID-xknown(:,1)).^2/norm(xknown(:,1),2)^2 +
(kpar(1)*ID-xknown(:,2)).^2/norm(xknown(:,2),2)^2 +
(kpar(4)*ID-xknown(:,4)).^2/norm(xknown(:,4),2)^2 +
(kpar(3)/100*IH-xknown(:,3)).^2/norm(xknown(:,3),2)^2;

Error in
optimize_CT_Uttar_Bastar_Kanker>@(kpar)integrate(kpar,xknown,N,R,ID,IH0,D,k3poly)
(line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)

Error in snls (line 342)
            newfvec = feval(funfcn{3},xcurr,varargin{:});

Error in lsqncommon (line 164)
            snls(funfcn,xC,lb,ub,flags.verbosity,options,defaultopt,initVals.F,initVals.J,caller,
            ...

Error in lsqnonlin (line 262)
   lsqncommon(funfcn,xCurrent,lb,ub,options,defaultopt,optimgetFlag,caller,...

Error in optimize_CT_Uttar_Bastar_Kanker (line 73)
[kpar,resnorm]=lsqnonlin(@(kpar)
integrate(kpar,xknown,N,R,ID,IH0,D,k3poly),kpar,[],[],options)
} 
slurmstepd: error: *** JOB 2291 ON n001 CANCELLED AT 2021-03-25T19:20:43 ***
parallel: SIGTERM received. No new jobs will be started.
parallel: Waiting for these 64 jobs to finish. Send SIGTERM again to stop now.
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Deoria
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_OR_Cuttack
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MH_Nanded
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_WB_Nadia
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MH_Latur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_TN_Erode
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_ML_Ribhoi
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_KL_Kozhikode
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_WB_Malda
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_RJ_Bikaner
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Amethi
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_JH_Koderma
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_JK_Jammu
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_BR_West_Champaran
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_BR_Bhagalpur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UT_Bageshwar
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_AR_Dibang_Valley
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_HR_Nuh
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Patiala
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UT_Pithoragarh
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_AR_Changlang
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_CT_Mahasamund
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MP_Dindori
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Azamgarh
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_GJ_Gir_Somnath
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_TR_Unokoti
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MP_Satna
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Unnao
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_GJ_Rajkot
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_CT_Balod
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PY_Yanam
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_GJ_Sabarkantha
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Sonbhadra
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_BR_Buxar
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Sangrur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Auraiya
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_ML_North_Garo_Hills
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_HR_Kaithal
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_TN_Cuddalore
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Sri_Muktsar_Sahib
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_KA_Yadgir
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_WB_Jhargram
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Balrampur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_CT_Jashpur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_UP_Maharajganj
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_OR_Puri
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_HP_Bilaspur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Barnala
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_TN_Kanyakumari
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_KL_Wayanad
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_OR_Sundargarh
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Hoshiarpur
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_KA_Hassan
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_RJ_Ganganagar
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Fazilka
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_PB_Bathinda
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MP_Ujjain
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_GJ_Aravalli
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_WB_Paschim_Bardhaman
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_KL_Ernakulam
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_TR_West_Tripura
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_TN_Tiruchirappalli
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MH_Amravati
parallel: /software/Matlab/bin/matlab -nodisplay -r optimize_MH_Washim
